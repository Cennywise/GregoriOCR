Team: Janice Adams, Keiran Hozven-Farley, Tori Tomlinson

***
# **Project: Corpus of Chords**
***
 * Data:  
    * Our project uses a dataset of [Bach Chorales](https://github.com/czhuang/JSB-Chorales-dataset) hosted on Github in MIDI note numbers.
    * See documentation in playground.py for information on preprocessing the data (for example, removing repeated chords).
    * This dataset feeds into our word2vec algorithm. The embeddings outputted by word2vec are used as inputs to our MIDI file generator and Kmeans algorithms.
      
 * Word2Vec:  
    * We use an implementation of the Word2Vec algorithms modeled on this [tensorflow tutorial](https://www.tensorflow.org/tutorials/text/word2vec).
    https://www.tensorflow.org/tutorials/text/word2vec
    * word2vec is an algorithm that generates n dimensional representations of words such that related chords are close to eacher in
    euclidian space. It does this by iterating through the dataset to find positive and negative skip grams, and posing a catagorization problem between them by taking the dot product of the pairs and seeing if it is sufficiently small. The Weights generated by the embedings layer of the model (the one that translates between psuedo one-hot encodings of the word and vectors in n-space) then become our chord vectors.

 * Generator 
    * Once a set of embeddings is obtained, we generate new sequences by assosiating each embedding vector with its N closest neighbors, choosing a starting vector arbitrarily, than iterativly tracing a path through the embedding space by moving to neighbors. The model cannot account for rhythem, however by holding notes whenever they are repeated in adjacent chords we end up with some rhythem as an emergant property.

 * Kmeans:  
    * We used two Kmeans algorithms - one is a student-implemented algorithm from MAT167 HW4 (Chandler's summer 2022 course), the other is a pre-built implementation from sklearn. Both are run on the embeddings list outputted from Word2Vec. 
    * Then we match up the partitioned weights with information from music21 to view the chord names, root tones, and quality (major/minor/etc) in each partition. 
      
 * Tables:  
   * Our tables list the partitions, and for each partition displays the top n most common chords given a feature (chord name, chord root, or chord quality). 
   * See 'Analysis' 
   * See the text files in the OutputAnalysis folder for the following tables (ran from a word2vec with dimension=128 and negative sampling=15)(k=number of clusters):
      * KmeansStudent_ChordName_d_128_n_15_k_24
      * KmeansStudent_Root_d_128_n_15_k_24
      * KmeansStudent_Quality_d_128_n_15_k_24
      * SKlearn_ChordName_d_128_n_15_k_24
      * SKlearn_Root_d_128_n_15_k_24
      * SKlearn_Quality_d_128_n_15_k_24
      * SKlearn_ChordName_128_n_15_k_12
      * SKlearn_ChordName_d_128_n_15_k_48
      
    
## **How to use this machine learning project**  

DISCLAIMER ON PROGRAMMATIC NAVIGATION OF THE PROJECT DIRECTORY
   this project was done on three different machines, a windows laptop, a chromebook, and a linux virtual machine
   as such there is some consistancy with how files are acsessed. Attempts have been made to remedy this but none of us really
   know what we are doing here, there may be file not found errors on your machine.

  Data 
   	If you use your own data, it must be in the same format as the JSB Chorals Dataset: four note chords, with -1 for empty note. See playground.py for additional documentation on data preprocessing functions. Our generator and Kmeans use the embeddings generated by word2vec - see word2vec_notebook and Kmeans notebooks for how to save and load this.
	
1. Install the following Python libraries:
		tabulate
		numpy
		tensorflow
		tensorboard
		keras
		sklearn (aka scikit-learn)
		mido
      		music21

   2. Clone the corpus-of-chords repo.
   3. In corpus-of-chords, navigate to the Data/Corpi/ folder to find a dataset to run on. You can use our pre-configured datasets, or use the buildDataset function in playground.py to generate your own varient from the raw dataset "Jsb16thSeperated(RAW)) ". DO NOT RUN MODEL ON THE RAW DATASET, IT HAS NOT BEEN PREPROSESSED.
   3. Open the word2vec_notebook, and follow the instructions written therein to train a model on your chosen dataset. Be sure to run the cells that writes the output (logs, embeddings, etc) to disk.
   4. From here, there are three things you can do with the generated embeddings:
      a. Visualise the data in the tensorboard embeddings projector. Run tensorboard from the apropriate tensorboard data folder, located in the folder assosiated with your dataset. YOU MUST PLACE THE METADATA GENERATED BY buildDataset INTO THIS FOLDER YOURSELF, before running tensorboard, in order to get labels on your embedings. 
      b. Generate new chord sequence midi file. Run generationModel in playground.py, feeding it the name of the dataset you used and the name of the model you generated. Next run generateSequence, feeding it the length of the sequence and the same information you fed generationModel. A midi file will be output into the root project directory. 
      c. Clustering. You can open either the KmeansSklearn or KmeansStudentAlgorithm notebooks and follow the instructions written therein to run the respective Kmeans algorithm and generate tables displaying information about the partitions. 
 

##
