{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034abf95",
   "metadata": {},
   "source": [
    "# <center>Music Prediction and Generation</center>\n",
    "\n",
    "\n",
    "In this notebook, we present our MIDI-to-genre prediction model and generator, and how to use the notebook to process your own dataset, train it, and generate .mid files with it.\n",
    "\n",
    "<b>The first thing you want to do is to change the value of `WORKING_DIRECTORY` to the directory which contains the \\Data folder</b>. So for example, C:\\Users\\name\\Music Prediction and Synthesis\\Data. This should be set as os.getcwd() by default, unless you've downloaded it and ran the notebook elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfb3a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##make sure to set WORKING_DIRECTORY to where the 'Data' folder is at\n",
    "WORKING_DIRECTORY = r\"C:\\Users\\harki\\MAT180_Final_Project\\Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014d463a",
   "metadata": {},
   "source": [
    "Now, to upload your own .mid samples, create a folder with the genre name in \\Data, and put the corresponding .mid files in this folder. There are already 18 folders by default of popular genres, so you can put your .mid files in there instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107254b6",
   "metadata": {},
   "source": [
    "# Essential imports and ground constants\n",
    "Run everything in the following cells to get basic data and imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b25eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import mido\n",
    "from mido import MidiFile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import random, time\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import math\n",
    "from sklearn.datasets import fetch_openml\n",
    "from json import JSONEncoder\n",
    "\n",
    "##this specifies how deep to search every folder in 'Data'.\n",
    "FILE_DEPTH = 3\n",
    "\n",
    "##this specifies how many notes we want to compute later, quantized to sixteenth notes\n",
    "##so 8 bars in common time is equal to a capacity of 128\n",
    "CAPACITY = 256\n",
    "\n",
    "##if our dataset grows, change this to reflect new genres added\n",
    "##alternatively, we can use the number of keys in genres_dict instead.\n",
    "UNIQUE_GENRES = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc03bba3",
   "metadata": {},
   "source": [
    "# Important preprocessing methods\n",
    "Run everything below to get necessary methods for preprocessing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ec5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memoize(f):\n",
    "    Cache = {}\n",
    "    \n",
    "    def f_memoized(*args):\n",
    "        if (f, args) in Cache:\n",
    "            return Cache[(f, args)]\n",
    "        result = f(*args)\n",
    "        Cache[(f, args)] = result\n",
    "        return result\n",
    "    \n",
    "    return f_memoized\n",
    "\n",
    "def getNotes(mid,trackNo):\n",
    "    notes = []\n",
    "    for msg in mid.tracks[trackNo]:\n",
    "        if msg.type == 'note_on':\n",
    "            notes.append(msg)\n",
    "    return notes  \n",
    "\n",
    "def getNotesTrack(track):\n",
    "    notes = []\n",
    "    for msg in track:\n",
    "        if msg.type == 'note_on':\n",
    "            notes.append(msg)\n",
    "    return notes\n",
    "\n",
    "def quantize16(notes):\n",
    "    for i in range(len(notes)):\n",
    "        if notes[i].velocity == 0 and notes[i].time > 50 and notes[i].time <= 60:\n",
    "            notes[i] = notes[i].copy(time = 113)\n",
    "    return notes\n",
    "\n",
    "def absolutize(notes):\n",
    "    #this methods returns a dictionary with notes matching the exact time\n",
    "    for i in range(1,len(notes)):\n",
    "        notes[i] = notes[i].copy(time = notes[i].time + notes[i-1].time)\n",
    "    return notes\n",
    "\n",
    "#input is list of notes, capacity, padding and removeZeroVelocities\n",
    "def trim(notes,capacity, pad = True, removeZeroVelocities = True):\n",
    "    trimmed = []\n",
    "    count = 0\n",
    "    \n",
    "    notesToDel = []\n",
    "    if removeZeroVelocities == True:\n",
    "        for i in range(len(notes)):\n",
    "            if notes[i].velocity == 0:\n",
    "                notesToDel.append(notes[i])\n",
    "    \n",
    "    for item in notesToDel:\n",
    "        notes.remove(item)\n",
    "    \n",
    "    \n",
    "    \n",
    "    while count < capacity and count < len(notes):\n",
    "        trimmed.append(notes[count])\n",
    "        count += 1\n",
    "    if pad == True:\n",
    "#         emptyNote = mido.Message('note_on', velocity = 0)\n",
    "        i = 0\n",
    "        while len(trimmed) < capacity:\n",
    "            trimmed.append(notes[i])\n",
    "            i += 1\n",
    "            if i >= len(notes):\n",
    "                i = 0\n",
    "\n",
    "    return trimmed\n",
    "\n",
    "# @memoize\n",
    "def getMidiFile(target):\n",
    "    path = WORKING_DIRECTORY\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            if name == target:\n",
    "                targetLocation = os.getcwd()\n",
    "                filepath = root + os.sep\n",
    "\n",
    "    os.chdir(filepath)\n",
    "    return MidiFile(target, clip = True)\n",
    "\n",
    "#takes a MidiFile and returns only the trimmed notes\n",
    "def compress(midiFile, pad = True, removeZeroVelocities = True):\n",
    "    list = []\n",
    "    for tracks in midiFile.tracks:\n",
    "        list.append(tracks)\n",
    "    \n",
    "    merged = mido.merge_tracks(list)\n",
    "    merged = getNotesTrack(merged)\n",
    "    merged = trim(merged, CAPACITY, pad, removeZeroVelocities)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def encoder(genre):\n",
    "    length = len(genres_dict.keys())\n",
    "\n",
    "    list = []\n",
    "\n",
    "    for keys in genres_dict.keys():\n",
    "        list.append(keys)\n",
    "        \n",
    "    output = np.zeros(len(list))   \n",
    "    for j in range(len(list)):\n",
    "        if genre == list[j]:\n",
    "            output[j] = 1       \n",
    "    return output\n",
    "\n",
    "def decoder(array):\n",
    "    list = []\n",
    "    for keys in genres_dict.keys():\n",
    "        list.append(keys)\n",
    "    index = np.argmax(array)\n",
    "\n",
    "    return list[index]\n",
    " \n",
    "def genADLData(size):\n",
    "    list = []\n",
    "    for key in genres_dict.keys():\n",
    "        list.append(key)\n",
    "    genres = []\n",
    "     \n",
    "    for i in range(size):\n",
    "        r = random.randint(0,len(list)-1)\n",
    "        genres.append(list[r])\n",
    "    \n",
    "    music = []\n",
    "    for item in genres:\n",
    "        music = music + random.sample(genres_dict[item],1)    \n",
    "    return genres,music\n",
    "\n",
    "#gets MidiFiles from a list with str music entires\n",
    "def getMidiList(musicList):\n",
    "    for i in range(len(musicList)):\n",
    "        musicList[i] = getMidiFile(musicList[i])\n",
    "    return musicList\n",
    "        \n",
    "#gets only notes from a list with str music entries\n",
    "def getNotesFromList(musicList):\n",
    "    outputList = []\n",
    "    for i in range(len(musicList)):\n",
    "        outputList.append( musicList[i].note )\n",
    "    return outputList\n",
    "\n",
    "def getTimesFromList(musicList):\n",
    "    outputList = []\n",
    "    for i in range(len(musicList)):\n",
    "        outputList.append( musicList[i].time )\n",
    "    return outputList\n",
    "\n",
    "def getVelocitiesFromList(musicList):\n",
    "    outputList = []\n",
    "    for i in range(len(musicList)):\n",
    "        outputList.append( musicList[i].velocity )\n",
    "    return outputList\n",
    "\n",
    "def compressListofNames(genre,music):\n",
    "    outputList = []\n",
    "    for i in range(len(music)):\n",
    "        if i > 1 and i % 100 == 0:\n",
    "            print(\"Compressed\",i,\"files so far.\")\n",
    "        try:\n",
    "            outputList.append( compress(getMidiFile(music[i])) )\n",
    "        except:\n",
    "            print(music[i],\"caused an error! Ignoring this file for compression.\")\n",
    "            del genre[i]\n",
    "    return outputList\n",
    "\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6ea2de",
   "metadata": {},
   "source": [
    "# Forming genres_dict\n",
    "From the folder 'Data', we create a dictionary `genres_dict` which contains keys as genres and elements of that key as lists of music associated with that genre. If you want to load the entire set which contains corrupted data as well, run the following cell. If you want to use the default samples, skip to <b>Load Uncorrupted Genres_Dict</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249cb79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collects midi files from a given folder\n",
    "def collect_midi_files(midi_files):\n",
    "    for element in os.listdir():\n",
    "        if os.path.isdir(os.getcwd() + \"/\" + element):\n",
    "            # print(f'folder: {element}')\n",
    "            os.chdir(os.getcwd() + \"/\" + element)\n",
    "            midi_files = collect_midi_files(midi_files)\n",
    "            os.chdir(\"..\")\n",
    "        elif element.endswith(\".mid\"): # change to .mid\n",
    "            # print(f'file: {element}')\n",
    "            midi_files.append(element)\n",
    "    return midi_files\n",
    "\n",
    "os.chdir(WORKING_DIRECTORY)\n",
    "\n",
    "genres_dict = {}\n",
    "\n",
    "for element in os.listdir():\n",
    "    if os.path.isdir(os.getcwd() + \"/\" + element):\n",
    "        os.chdir(os.getcwd() + \"/\" + element)\n",
    "        midi_names = []\n",
    "        midi_names = collect_midi_files(midi_names)\n",
    "        if midi_names != []:\n",
    "            genres_dict[element] = midi_names\n",
    "        os.chdir(\"..\")\n",
    "\n",
    "print(genres_dict)\n",
    "\n",
    "count = 0\n",
    "for keys in genres_dict.keys():\n",
    "    for list in genres_dict[keys]:\n",
    "        count += 1\n",
    "print(\"\\ngenres_dict has\",count,\"elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d72b8c",
   "metadata": {},
   "source": [
    "Like many massive datasets uncautiously curated, there are corrupted data. Below is an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14174ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example corrupted Midi file\n",
    "mid = getMidiFile('Fig Leaf Rag.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c579a5",
   "metadata": {},
   "source": [
    "This method below removes all corrupted data from genres_dict. Running cleanData() will take approximately an hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6d69d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genres_dict = {'Ambient':['Fig Leaf Rag.mid','Edvard Grieg Ich liebe dich.mid']}\n",
    "@memoize\n",
    "def cleanData():\n",
    "    errorCount = 0\n",
    "    count = 0\n",
    "    for keys in genres_dict.keys():\n",
    "        for item in genres_dict[keys]:\n",
    "            if count%100 == 0 and count > 1:\n",
    "                print(\"Went through\",count,\"files so far.\")\n",
    "            try:\n",
    "                getMidiFile(item)\n",
    "            except:\n",
    "                genres_dict[keys].remove(item)\n",
    "                errorCount += 1\n",
    "            count += 1\n",
    "\n",
    "    count = 0\n",
    "    for keys in genres_dict.keys():\n",
    "        for list in genres_dict[keys]:\n",
    "            count += 1\n",
    "    print(\"There were\",errorCount,\"corrupted files.\")\n",
    "    print(\"Uncorrupted genres_dict has\",count,\"files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c665158",
   "metadata": {},
   "outputs": [],
   "source": [
    "##takes approximately an hour\n",
    "cleanData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0395782",
   "metadata": {},
   "source": [
    "# Load Uncorrupted genres_dict\n",
    "This cell below returns `genres_dict` just like above, but without corrupted files and is much faster. If you are using your own samples, this will not load them, and you will have to perform the operations in the cells above to load your own samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfa69bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(WORKING_DIRECTORY)\n",
    "os.chdir(\"..\")\n",
    "\n",
    "with open('uncorrupted.txt') as f:\n",
    "    data = f.read()\n",
    "\n",
    "genres_dict = json.loads(data)\n",
    "\n",
    "print(genres_dict)\n",
    "count = 0\n",
    "for keys in genres_dict.keys():\n",
    "    for list in genres_dict[keys]:\n",
    "        count += 1\n",
    "print(\"\\nUncorrupted genres_dict has\",count,\"elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e9e5e7",
   "metadata": {},
   "source": [
    "# Neural Network functions\n",
    "\n",
    "Running the cell below gives you absolutely everything you need for a feedfoward neural network we will use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aed056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to import needed modules and define plotting functions (no input needed)\n",
    "# function to plot costs\n",
    "def plot_costs(costs):\n",
    "    plt.plot(costs)\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"cost\")\n",
    "    plt.show()\n",
    "    \n",
    "# function to plot costs\n",
    "def plot_grads(grads):\n",
    "    plt.plot(grads)\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"gradient norm\")\n",
    "    plt.show()\n",
    "\n",
    "# defining a function to plot data\n",
    "def plot_data(X,Y,size_ = 2):\n",
    "    m = len(X)\n",
    "    plot_figure = go.Figure(data=[go.Scatter3d(x=X[:,0], y=X[:,1], z=[r[0] for r in Y], mode='markers',marker=dict(size=size_))])\n",
    "    plotly.offline.iplot(plot_figure)\n",
    "\n",
    "# defining a function to plot models fit\n",
    "def plot_fit(X,Y,W,B,G,size_ = 2):\n",
    "    trace = go.Scatter3d(x=X[:,0], y=X[:,1], z=[r[0] for r in Y], mode='markers',marker=dict(size=size_))\n",
    "    xs,ys = X[:,0],X[:,1]\n",
    "    xxx = np.outer(np.linspace(min(xs), max(xs), 30), np.ones(30))\n",
    "    yyy = np.outer(np.linspace(min(ys), max(ys), 30), np.ones(30)).T\n",
    "    zzz = np.zeros([30,30])\n",
    "    D = len(G)-1\n",
    "    for i in range(30):\n",
    "        for j in range(30):\n",
    "            zzz[i,j] = feedforward(W,B,G,np.array([xxx[i,j],yyy[i,j]]))[D][0]\n",
    "    # Configure the layout.\n",
    "    layout = go.Layout(margin={'l': 0, 'r': 0, 'b': 0, 't': 0})\n",
    "    data = [trace,go.Surface(x=xxx, y=yyy, z=zzz, showscale=False, opacity=0.5)]\n",
    "    # Render the plot.\n",
    "    plot_figure = go.Figure(data=data, layout=layout)\n",
    "    plot_figure.update_layout(\n",
    "        scene = dict(\n",
    "            xaxis = dict(nticks=4, range=[min(X[:,0]),max(X[:,0])],),\n",
    "            yaxis = dict(nticks=4, range=[min(X[:,1]),max(X[:,1])],),\n",
    "            zaxis = dict(nticks=4, range=[min(Y),max(Y)],),),\n",
    "        width=700,\n",
    "        margin=dict(r=20, l=10, b=10, t=10))\n",
    "    plotly.offline.iplot(plot_figure)\n",
    "\n",
    "def ReLU(x,deriv = False):\n",
    "    if deriv == True:\n",
    "        Hx = []\n",
    "        for element in x:\n",
    "            if element >= 0:\n",
    "                Hx = Hx + [1]\n",
    "            else:\n",
    "                Hx = Hx + [0]\n",
    "        return np.diag(np.array(Hx)) \n",
    "    else:\n",
    "        Hx = []\n",
    "        for element in x:\n",
    "            if element >= 0:\n",
    "                Hx = Hx + [element]\n",
    "            else:\n",
    "                Hx = Hx + [0]\n",
    "        return np.array(Hx)\n",
    "\n",
    "def Linear(x,deriv = False):\n",
    "    if deriv == True:\n",
    "        if type(x) != np.ndarray:\n",
    "            return np.array([1])\n",
    "        else:\n",
    "            return np.eye(x.shape[0])\n",
    "    else:\n",
    "        Lx = []\n",
    "        for element in x:\n",
    "            Lx = Lx + [element]\n",
    "        return np.array(Lx)\n",
    "\n",
    "def Sigmoid(x,deriv = False):\n",
    "    if deriv:\n",
    "        return np.diag(Sigmoid(x,False)*(1-Sigmoid(x,False)))\n",
    "    return 1/(1+np.exp(-x))\n",
    "#     if deriv == True:\n",
    "#         y = Sigmoid(x,deriv = False)\n",
    "#         ones = np.ones(y.shape)\n",
    "#         return np.diag( y*(ones - y) )  \n",
    "#     else:\n",
    "#         Sgx = []\n",
    "#         for element in x:\n",
    "#             Sgx = Sgx + [1/(1+math.e**(-element))]\n",
    "#         return np.array(Sgx)\n",
    "\n",
    "def Squared(x,deriv = False):\n",
    "    if deriv:\n",
    "        return np.diag([2*x[i] for i in range(len(x))])\n",
    "    return x**2\n",
    "\n",
    "def Softmax(x,deriv = False):\n",
    "    if deriv:\n",
    "        gx = Softmax(x,deriv = False)\n",
    "        return np.diag(gx) - np.outer(gx,gx)\n",
    "    denom = sum([np.exp(x[i]) for i in range(len(x))])\n",
    "    return np.array([np.exp(x[i])/denom for i in range(len(x))])\n",
    "\n",
    "def loss(Nx,y,cost_type,deriv = False):\n",
    "    if deriv == True:\n",
    "        if cost_type == 'ce':\n",
    "            return -1*y.T*(1/Nx)    \n",
    "        elif cost_type == 'bce': \n",
    "            return -y/Nx + (1-y)/(1-Nx)  \n",
    "        else: \n",
    "            return 2*(Nx-y).T    \n",
    "    else:\n",
    "        if cost_type == 'ce':\n",
    "            return -1*y.T@np.log(Nx)\n",
    "        if cost_type == 'bce':\n",
    "            return -y.T@np.log(Nx) -(1-y).T@np.log(1-Nx)  \n",
    "        else:\n",
    "            return LA.norm(Nx-y,2)**2\n",
    "        \n",
    "def feedforward(W,B,G,x):\n",
    "    x0 = G[0](x)\n",
    "    s0 = W[0]@x0+B[0]\n",
    "    feeds = [ [x0,s0] ]    \n",
    "    depth = len(W)\n",
    "    for i in range(1,depth):\n",
    "        xi = G[i](feeds[i-1][1])\n",
    "        si = W[i]@xi+B[i]\n",
    "        feeds = feeds + [ [xi,si] ]   \n",
    "    xfinal = G[depth](feeds[depth-1][1])\n",
    "    feeds = feeds + [ xfinal ]\n",
    "    return feeds      \n",
    "\n",
    "def deltas(X_feeds,Y,W,B,G,verbose = False, cost_type = 'se'):\n",
    "    depth = len(W)\n",
    "    deltas_dict = {}\n",
    "    deltas_list = []\n",
    "    for key in X_feeds.keys():\n",
    "        Nx = X_feeds[key][-1]\n",
    "        y = Y[key]\n",
    "        sd_1 = X_feeds[key][-2][1]\n",
    "        delta_d_1 = loss(Nx, y, cost_type,deriv = True)@G[depth](sd_1,deriv = True)\n",
    "        deltas_list = deltas_list + [delta_d_1]\n",
    "        for l in range(depth-1,0,-1):\n",
    "            sl = X_feeds[key][l-1][1]\n",
    "            delta = deltas_list[-1]@W[l]@G[l](sl,deriv=True)\n",
    "            deltas_list = deltas_list + [delta]\n",
    "        deltas_list.reverse()\n",
    "        deltas_dict.update({key:deltas_list})\n",
    "    return deltas_dict\n",
    "\n",
    "def grads(X,Y,W,B,G,batch, lambda_ = 0, verbose = False,cost_type = 'se'):\n",
    "    X_feeds = {}\n",
    "    for i in batch:\n",
    "        xi = X[i,:]\n",
    "        X_feeds.update({i:feedforward(W,B,G,xi)})\n",
    "    depth = len(W)\n",
    "    dWs,dBs = [],[]\n",
    "    X_deltas = deltas(X_feeds,Y,W,B,G,verbose, cost_type)\n",
    "    for l in range(depth):\n",
    "        dWsum = 0\n",
    "        dBsum = 0\n",
    "        for i in batch:\n",
    "            x_l = X_feeds[i][l][0]\n",
    "            x_delta_l = X_deltas[i][l]\n",
    "            dWsum = dWsum + np.outer(x_delta_l,x_l) + 2*lambda_*W[l]\n",
    "            dBsum = dBsum + x_delta_l\n",
    "        dWs = dWs + [1/len(batch)*dWsum]\n",
    "        dBs = dBs + [1/len(batch)*dBsum]\n",
    "    return dWs,dBs,X_feeds\n",
    "\n",
    "def fit(X,Y,arch,G,alpha = 1e-9, momentum = .01, batch_size = 100, \n",
    "        lambda_ = 0, max_iters = 100,verbose = False, cost_type = 'se',print_costs = True):\n",
    "    W,B,VW,VB = [],[],[],[]\n",
    "    D,m = len(G)-1,len(X)\n",
    "    for l in range(D):\n",
    "        W = W + [ np.random.normal( 0, 2/(arch[l]+arch[l+1]), (arch[l+1],arch[l]) ) ]\n",
    "        B = B + [ np.zeros(arch[l+1])]\n",
    "        VW = VW + [np.zeros(W[l].shape)]\n",
    "        VB = VB + [np.zeros(B[l].shape)]\n",
    "    epochs = 0\n",
    "    costs = []\n",
    "    tempcosts = []\n",
    "    grad_norms = []\n",
    "    while epochs <= max_iters:\n",
    "        if epochs%(np.floor(max_iters/30))==0 and print_costs == True and costs != []:\n",
    "            print(f'epoch: {epochs}')\n",
    "            print(f'           cost: {costs[-1]}')\n",
    "        batch = random.sample(range(m),batch_size)\n",
    "        dWs,dBs,feeds = grads(X,Y,W,B,G,batch,lambda_,verbose,cost_type)\n",
    "        for i in range(len(dWs)):\n",
    "            norm = LA.norm(dWs[i],2) + LA.norm(dBs[i],2)\n",
    "            grad_norms = grad_norms + [ norm ]\n",
    "        tempCosts = 0\n",
    "        for i in batch:\n",
    "            Nx = feeds[i][D]\n",
    "            y = Y[i]\n",
    "            J = loss(Nx,y,cost_type)\n",
    "            tempCosts = tempCosts + J/len(batch)\n",
    "        costs = costs + [tempCosts]\n",
    "        for l in range(D):\n",
    "            VW[l] = momentum*VW[l] - alpha*dWs[l]\n",
    "            VB[l] = momentum*VB[l] - alpha*dBs[l]\n",
    "            W[l] = W[l] + VW[l]\n",
    "            B[l] = B[l] + VB[l]\n",
    "        epochs = epochs + 1\n",
    "    return W,B,costs,grad_norms\n",
    "        \n",
    "def predict(W,B,G,x,output_type = 'vector'):\n",
    "    prediction = feedforward(W,B,G,x)[-1]\n",
    "    out = np.zeros(prediction.shape[0])\n",
    "    out[np.argmax(prediction)] = 1\n",
    "    \n",
    "    if output_type == 'vector':\n",
    "        return out\n",
    "    \n",
    "    elif output_type == 'genre':\n",
    "        return decoder(out)\n",
    "    \n",
    "def accuracy(X,y,W,B,G):\n",
    "    correct = 0\n",
    "    predictions = []\n",
    "    for examples in X:\n",
    "        predictions.append(predict(W,B,G,examples,output_type = 'genre'))\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        if predictions[i] == decoder(y[i]):\n",
    "            correct += 1\n",
    "            \n",
    "    return correct/len(y)\n",
    "\n",
    "def save(W,B,arch,G,location):\n",
    "    os.chdir(WORKING_DIRECTORY)\n",
    "    os.chdir('..')\n",
    "    os.chdir(os.getcwd() + '\\\\' + location)\n",
    "    jsonFile = open(\"weights.json\", \"w+\")\n",
    "    jsonFile.seek(0) # absolute file positioning\n",
    "    jsonFile.truncate() # to erase all data \n",
    "    jsonFile.close()\n",
    "    jsonFile = open(\"biases.json\", \"w+\")\n",
    "    jsonFile.seek(0) # absolute file positioning\n",
    "    jsonFile.truncate() # to erase all data \n",
    "    jsonFile.close()\n",
    "    jsonFile = open(\"arch.json\", \"w+\")\n",
    "    jsonFile.seek(0) # absolute file positioning\n",
    "    jsonFile.truncate() # to erase all data \n",
    "    jsonFile.close()\n",
    "    jsonFile = open(\"G.json\", \"w+\")\n",
    "    jsonFile.seek(0) # absolute file positioning\n",
    "    jsonFile.truncate() # to erase all data \n",
    "    jsonFile.close()\n",
    "    print('deleted old weights from weights.json and biases from biases.json')\n",
    "    # Serialization\n",
    "    Ws,Bs = {l:W[l] for l in range(len(W))},{l:B[l] for l in range(len(B))}\n",
    "    archs,Gs = {l:arch[l] for l in range(len(arch))},{l:str(G[l]) for l in range(len(G))}\n",
    "    print(\"saved to JSON files weights.json, biases.json, arch.json and G.json\")\n",
    "    with open(\"weights.json\", \"w\") as write_file:\n",
    "        json.dump(Ws, write_file, cls=NumpyArrayEncoder)\n",
    "    with open(\"biases.json\", \"w\") as write_file:\n",
    "        json.dump(Bs, write_file, cls=NumpyArrayEncoder)\n",
    "    with open(\"arch.json\", \"w\") as write_file:\n",
    "        json.dump(archs, write_file, cls=NumpyArrayEncoder)\n",
    "    with open(\"G.json\", \"w\") as write_file:\n",
    "        json.dump(Gs, write_file, cls=NumpyArrayEncoder)\n",
    "        \n",
    "def load(location):\n",
    "    os.chdir(WORKING_DIRECTORY)\n",
    "    os.chdir('..')\n",
    "    os.chdir(os.getcwd() + '\\\\' + location)\n",
    "    \n",
    "    fileObject = open(\"weights.json\", \"r\")\n",
    "    jsonContent = fileObject.read()\n",
    "    Ws = json.loads(jsonContent)\n",
    "\n",
    "    fileObject = open(\"biases.json\", \"r\")\n",
    "    jsonContent = fileObject.read()\n",
    "    Bs = json.loads(jsonContent)\n",
    "\n",
    "    fileObject = open(\"arch.json\", \"r\")\n",
    "    jsonContent = fileObject.read()\n",
    "    archs = json.loads(jsonContent)\n",
    "\n",
    "    fileObject = open(\"G.json\", \"r\")\n",
    "    jsonContent = fileObject.read()\n",
    "    Gs = json.loads(jsonContent)\n",
    "\n",
    "    W = [np.array(Ws[i]) for i in Ws.keys()]\n",
    "    B = [np.array(Bs[i]) for i in Bs.keys()]\n",
    "    arch = [archs[i] for i in archs.keys()]\n",
    "    G = [eval(Gs[i][10:][:-22]) for i in Gs.keys()]\n",
    "\n",
    "    print(f'current best architecture: {arch}')\n",
    "    print(f'current best activation structure: {G}')\n",
    "    return W,B,arch,G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9997d4f",
   "metadata": {},
   "source": [
    "# Music Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff81c9fd",
   "metadata": {},
   "source": [
    "## Forming the dataset\n",
    "\n",
    "Now, we form the dataset readable by the NN, as well as labels, from the ADL files. The cell below will generate the usual dataset X before splitting into train, validation and test sets. Feel free to change value for `size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b632b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to load all default 11000 samples, you can set size to 11000.\n",
    "size = 3000 #must be at least 1!\n",
    "#takes approximately 10 minutes to load 1000 examples \n",
    "\n",
    "\n",
    "#list of genres and names of the music randomly sampled:\n",
    "removeZeroVelocities = True\n",
    "genres, music = genADLData(size)\n",
    "#since we are not interested in other midi metadata, and we are collapsing all tracks into one (chordizing), we\n",
    "#extract only the notes from the midi file associated with its name.\n",
    "notesList = compressListofNames(genres,music)\n",
    "\n",
    "#initialize and fill X\n",
    "X = np.atleast_2d(np.array(notesList[0]))\n",
    "for i in range(1,len(notesList)):\n",
    "    X_row = np.atleast_2d(np.array(notesList[i]))\n",
    "    X = np.concatenate((X,X_row),axis = 0)\n",
    "\n",
    "#fill Y, our labels\n",
    "Y = np.atleast_2d(np.array(genres)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8767cd05",
   "metadata": {},
   "source": [
    "## Creating train, test and validation sets\n",
    "After selecting a subset of the data, we have to split into three sets for each pitch, velocity and times. This means there will be 9 split sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b17063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating validation and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=3)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=4)\n",
    "\n",
    "#generate dataset of pitches only:\n",
    "def get_notes_from_dataset(X):\n",
    "    A = np.copy(X)\n",
    "    for example in A:\n",
    "        for i in range(len(example)):\n",
    "            example[i] = example[i].note\n",
    "    return A\n",
    "\n",
    "#generate dataset of velocities only:\n",
    "def get_velocities_from_dataset(X):\n",
    "    A = np.copy(X)\n",
    "    for example in A:\n",
    "        for i in range(len(example)):\n",
    "            example[i] = example[i].velocity\n",
    "    return A\n",
    "\n",
    "#generate dataset of time deltas only:\n",
    "def get_times_from_dataset(X):\n",
    "    A = np.copy(X)\n",
    "    for example in A:\n",
    "        for i in range(len(example)):\n",
    "            example[i] = example[i].time\n",
    "    return A\n",
    "\n",
    "X_pitches_train = get_notes_from_dataset(X_train)\n",
    "X_pitches_val = get_notes_from_dataset(X_val)\n",
    "X_pitches_test = get_notes_from_dataset(X_test)\n",
    "\n",
    "X_velocities_train = get_velocities_from_dataset(X_train)\n",
    "X_velocities_val = get_velocities_from_dataset(X_val)\n",
    "X_velocities_test = get_velocities_from_dataset(X_test)\n",
    "\n",
    "X_times_train = get_times_from_dataset(X_train)\n",
    "X_times_val = get_times_from_dataset(X_val)\n",
    "X_times_test = get_times_from_dataset(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d181b88",
   "metadata": {},
   "source": [
    "Now, let's encode `Y` with one-hot encoding. <b>Run this only once after running the previous cell.</b> (For some reason, I keep getting a FutureWarning error; this arises when using == to compare two different object types. But in the code below, everything is a string! I dont know how to solve this, but it computes exactly what is needed without fail.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8c2a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.copy(Y)\n",
    "\n",
    "length = len(genres_dict.keys())\n",
    "\n",
    "list = []\n",
    "A = A.flatten()\n",
    "A = A.tolist()\n",
    "\n",
    "for keys in genres_dict.keys():\n",
    "    list.append(keys)\n",
    "    \n",
    "for i in range(len(A)):\n",
    "    for j in range(len(list)):\n",
    "        if A[i] == list[j]:\n",
    "            A[i] = np.zeros(len(list))\n",
    "            A[i][j] = 1\n",
    "    \n",
    "# decoder(A[0])\n",
    "Y = np.array(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff219907",
   "metadata": {},
   "source": [
    "# Fitting it all\n",
    "And here we pick our architecture for our prediction model. We know that the last layer should have `Softmax` activation with (some number) of choices. We will use our prediction function to determine the accuracy later with `output_type = 'number'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99158daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this cell to get critical information about how our architecture should be, among other info\n",
    "print(\"Input size is\",CAPACITY)\n",
    "print(\"Current directory is pointed to\",WORKING_DIRECTORY)\n",
    "print(\"Output size (number of genres) is\",len(genres_dict.keys()))\n",
    "print(\"Pitch training size:\",X_pitches_train.shape)\n",
    "# print(\"Velocity Training size:\",X_velocities_train.shape)\n",
    "# print(\"Time Deltas Training size:\",X_times_train.shape)"
   ]
  },
  {
   "attachments": {
    "Untitled.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "7e831366",
   "metadata": {},
   "source": [
    "![Untitled.png](attachment:Untitled.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd03aec",
   "metadata": {},
   "source": [
    "## Pitch NN\n",
    "The cells in this section will define and test the feedforward neural network for fitting note pitches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ee574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select your architecture by changing, adding or removing values between CAPACITY and UNIQUE_GENRES\n",
    "arch_pNN = [CAPACITY, 64,64, UNIQUE_GENRES]\n",
    "\n",
    "#select activations available under Neural Network Functions section\n",
    "G_pNN = [Linear, Squared, Linear, Softmax]\n",
    "\n",
    "#choose parameters for the pitch NN\n",
    "alpha_pNN = 1e-5\n",
    "momentum_pNN = .99\n",
    "batch_size_pNN = 1700\n",
    "lambda_pNN = 0.0006\n",
    "max_iters_pNN = 300\n",
    "cost_type_pNN = 'se'\n",
    "\n",
    "W_pNN,B_pNN,costs_pNN,grad_norms_pNN = fit(X_pitches_train,y_train,arch_pNN,G_pNN,alpha_pNN, \n",
    "                                momentum_pNN,batch_size_pNN,lambda_pNN,max_iters_pNN,cost_type = cost_type_pNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f0c5c6",
   "metadata": {},
   "source": [
    "The following cells can be used to evaluate performance on the pitch NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d48e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Costs per batch\")\n",
    "plot_costs(costs_pNN)\n",
    "print(\"Grad_norms cost per batch\")\n",
    "plot_costs(grad_norms_pNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48275f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on the train set:\",accuracy(X_pitches_train,y_train,W_pNN,B_pNN,G_pNN))\n",
    "print(\"Accuracy on the validation set:\",accuracy(X_pitches_val,y_val,W_pNN,B_pNN,G_pNN))\n",
    "print(\"Accuracy on the test set:\",accuracy(X_pitches_test,y_test,W_pNN,B_pNN,G_pNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494931ca",
   "metadata": {},
   "source": [
    "### Saving good architectures\n",
    "Save your best architecture, activations, weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24bddbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save(W_pNN,B_pNN,arch_pNN,G_pNN,'Pitch NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bae383",
   "metadata": {},
   "source": [
    "### Loading good architectures\n",
    "Load the saved architecture, activations, weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822beed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W_pNN,B_pNN,arc_pNN,G_pNN = load('Pitch NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8473bc54",
   "metadata": {},
   "source": [
    "## Velocity NN\n",
    "The cells in this section will define and test the feedforward neural network for fitting note velocities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select your architecture by changing, adding or removing values between CAPACITY and UNIQUE_GENRES\n",
    "arch_vNN = [CAPACITY, 120, 100, UNIQUE_GENRES]\n",
    "\n",
    "#select activations available under Neural Network Functions section\n",
    "G_vNN = [Linear, ReLU, ReLU, Softmax]\n",
    "\n",
    "#choose parameters for the velocity NN\n",
    "alpha_vNN = 0.05\n",
    "momentum_vNN = .8\n",
    "batch_size_vNN = 60\n",
    "lambda_vNN = 0.00003\n",
    "max_iters_vNN = 5000\n",
    "cost_type_vNN = 'se'\n",
    "\n",
    "\n",
    "W_vNN,B_vNN,costs_vNN,grad_norms_vNN = fit(X_velocities_train,y_train,arch_vNN,G_vNN,alpha_vNN, \n",
    "                                momentum_vNN,batch_size_vNN,lambda_vNN,max_iters_vNN,cost_type = cost_type_vNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25a44b2",
   "metadata": {},
   "source": [
    "The following cells can be used to evaluate performance on the velocity NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deda9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Costs per batch\")\n",
    "plot_costs(costs_vNN)\n",
    "print(\"Grad_norms cost per batch\")\n",
    "plot_costs(grad_norms_vNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f743a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on the train set:\",accuracy(X_velocities_train,y_train,W_vNN,B_vNN,G_vNN))\n",
    "print(\"Accuracy on the validation set:\",accuracy(X_velocities_val,y_val,W_vNN,B_vNN,G_vNN))\n",
    "print(\"Accuracy on the test set:\",accuracy(X_velocities_test,y_test,W_vNN,B_vNN,G_vNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c520ea56",
   "metadata": {},
   "source": [
    "### Saving good architectures\n",
    "Save your best architecture, activations, weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08f2100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save(W_vNN,B_vNN,arch_vNN,G_vNN,'Velocity NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cfefdb",
   "metadata": {},
   "source": [
    "### Loading good architectures\n",
    "Load the saved architecture, activations, weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd8b63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "W_vNN,B_vNN,arc_vNN,G_vNN = load('Velocity NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a82a614",
   "metadata": {},
   "source": [
    "## Time Deltas NN\n",
    "The cells in this section will define and test the feedforward neural network for fitting note time deltas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf82fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select your architecture by changing, adding or removing values between CAPACITY and UNIQUE_GENRES\n",
    "arch_tNN = [CAPACITY,20,20,18,UNIQUE_GENRES]\n",
    "\n",
    "#select activations available under Neural Network Functions section\n",
    "G_tNN = [Linear, ReLU,Linear, Linear, Softmax]\n",
    "\n",
    "#choose parameters for the pitch NN\n",
    "alpha_tNN = 1e-3\n",
    "momentum_tNN = 0.9\n",
    "batch_size_tNN = 1700\n",
    "lambda_tNN = .000001\n",
    "max_iters_tNN = 300\n",
    "cost_type_tNN = 'se'\n",
    "\n",
    "W_tNN,B_tNN,costs_tNN,grad_norms_tNN = fit(X_times_train,y_train,arch_tNN,G_tNN,alpha_tNN, \n",
    "                                momentum_tNN,batch_size_tNN,lambda_tNN,max_iters_tNN,cost_type = cost_type_tNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cb16ac",
   "metadata": {},
   "source": [
    "The following cells can be used to evaluate performance on the time deltas NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda595cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Costs per batch\")\n",
    "plot_costs(costs_tNN)\n",
    "print(\"Grad_norms cost per batch\")\n",
    "plot_costs(grad_norms_tNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d86b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on the train set:\",accuracy(X_times_train,y_train,W_tNN,B_tNN,G_tNN))\n",
    "print(\"Accuracy on the validation set:\",accuracy(X_times_val,y_val,W_tNN,B_tNN,G_tNN))\n",
    "print(\"Accuracy on the test set:\",accuracy(X_times_test,y_test,W_tNN,B_tNN,G_tNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2626789",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(WORKING_DIRECTORY)\n",
    "mid = getMidiFile(\"La-La-La.mid\")\n",
    "print(mid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81faa8d2",
   "metadata": {},
   "source": [
    "### Saving good architectures\n",
    "Save your best architecture, activations, weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0206f41c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save(W_tNN,B_tNN,arch_tNN,G_tNN,'Time Deltas NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd089250",
   "metadata": {},
   "source": [
    "### Loading good architectures\n",
    "Load the saved architecture, activations, weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecdeedc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W_tNN,B_tNN,arc_tNN,G_tNN = load('Time Deltas NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746dad1c",
   "metadata": {},
   "source": [
    "# Music Generator\n",
    "The cell below is the music generation algorithm. The method `generate` takes in a genre, a tolerance value, and parameters detailing note ranges, velocity ranges and time delta ranges. Run the cell below to get the neccessary functions for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbce995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attributeAccuracy(messageList, genre, attribute):\n",
    "    if attribute == 'notes':\n",
    "        vector = getNotesFromList(messageList)\n",
    "        W,B,G = W_pNN, B_pNN, G_pNN\n",
    "        \n",
    "    elif attribute == 'velocities':\n",
    "        vector = getVelocitiesFromList(messageList)\n",
    "        W,B,G = W_vNN, B_vNN, G_vNN\n",
    "        \n",
    "    elif attribute == 'times':\n",
    "        vector = getTimesFromList(messageList)\n",
    "        W,B,G = W_tNN, B_tNN, G_tNN\n",
    "        \n",
    "    else:\n",
    "        print(\"Provide a valid attribute value.\")\n",
    "        \n",
    "    probability = feedforward(W,B,G,vector)[-1]\n",
    "    correctIndex = np.argmax(encoder(genre))\n",
    "    \n",
    "    return probability[correctIndex]        \n",
    "\n",
    "def generate(notesList, genre, tolerance, lowPitch, hiPitch, lowVel, hiVel, lowTimes, hiTimes):\n",
    "    generatedOutput = notesList\n",
    "    \n",
    "    emptyNote = mido.Message('note_on')\n",
    "    accuracy = 0\n",
    "    i = len(notesList)\n",
    "    \n",
    "    for j in range(i,CAPACITY):\n",
    "        generatedOutput.append(emptyNote)\n",
    "    \n",
    "    while accuracy < tolerance and i < len(generatedOutput):\n",
    "        #between A1 and G6\n",
    "        pitch_pool = [*range(lowPitch,hiPitch)]\n",
    "        #between piano and fortissimo\n",
    "        velocity_pool = [*range(lowVel,hiVel)]\n",
    "        #between semiquaver and semibreve\n",
    "        times_pool = [*range(lowTimes,hiTimes)]\n",
    "        \n",
    "        bestPitchAccuracy = 0\n",
    "        bestVelocityAccuracy = 0\n",
    "        bestTimesAccuracy = 0\n",
    "        \n",
    "        #new pitch\n",
    "        for itemInPitchPool in pitch_pool:\n",
    "            generatedOutput[i] = generatedOutput[i].copy( note = itemInPitchPool )\n",
    "            pitchAcc = attributeAccuracy(generatedOutput,genre, 'notes')\n",
    "            if pitchAcc > bestPitchAccuracy:\n",
    "                bestPitchAccuracy = pitchAcc\n",
    "                bestPitch = itemInPitchPool\n",
    "        generatedOutput[i] = generatedOutput[i].copy(note=bestPitch)\n",
    "        \n",
    "        #associated velocity\n",
    "        for itemInVelocityPool in velocity_pool:\n",
    "            generatedOutput[i] = generatedOutput[i].copy(velocity=itemInVelocityPool)\n",
    "            velocityAcc = attributeAccuracy(generatedOutput,genre, 'velocities')\n",
    "            if velocityAcc > bestVelocityAccuracy:\n",
    "                bestVelocityAccuracy = velocityAcc\n",
    "                bestVelocity = itemInVelocityPool\n",
    "        generatedOutput[i] = generatedOutput[i].copy(velocity=bestVelocity)\n",
    "        \n",
    "        #associated time delta\n",
    "        for itemInTimesPool in times_pool:\n",
    "            generatedOutput[i] = generatedOutput[i].copy(time=itemInTimesPool)\n",
    "            timesAcc = attributeAccuracy(generatedOutput,genre, 'times')\n",
    "            if timesAcc > bestTimesAccuracy:\n",
    "                bestTimesAccuracy = timesAcc\n",
    "                bestTime = itemInTimesPool\n",
    "        generatedOutput[i] = generatedOutput[i].copy(time=bestTime)\n",
    "        \n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        accuracy = (bestPitchAccuracy+bestVelocityAccuracy+bestTimesAccuracy)/3\n",
    "    return generatedOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9792b83",
   "metadata": {},
   "source": [
    "## Generate something!\n",
    "In the immediate cell below, edit some values and run it to generate a .mid file! Depending on `CAPACITY`, this will take a while. For a capacity of 256, this takes 3 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44918856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mido import Message, MidiFile, MidiTrack\n",
    "\n",
    "\n",
    "####################EDIT THESE PARAMETERS####################\n",
    "genre = 'Soundtracks'\n",
    "tolerance = 1\n",
    "\n",
    "lowest_pitch = 21 #A1 on a piano\n",
    "highest_pitch = 108 #C8 on a piano\n",
    "\n",
    "quietest_note = 33 #pianissimo\n",
    "loudest_note = 127 #fortissimo\n",
    "\n",
    "slowest_note = 1808 #semibreve (whole note)\n",
    "fastest_note = 113 #semiquaver (sixteenth note)\n",
    "###################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out = generate([], genre, tolerance, lowest_pitch, highest_pitch, quietest_note, loudest_note, fastest_note, slowest_note)\n",
    "\n",
    "os.chdir(WORKING_DIRECTORY)\n",
    "os.chdir('..')\n",
    "os.chdir(os.getcwd() + \"\\\\\" + \"Output\")\n",
    "\n",
    "mid = MidiFile()\n",
    "track = MidiTrack()\n",
    "\n",
    "for msg in out:\n",
    "    track.append(msg)\n",
    "    \n",
    "mid.tracks.append(track)\n",
    "\n",
    "mid.save('output_song.mid')\n",
    "print(\"Saved output_song.mid to \" + os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e38f583",
   "metadata": {},
   "source": [
    "# Remarks\n",
    "The output should resemble the correct genre as close as the given `tolerance`. Better NN models will yield better results. This algorithm works by going through every possible pitch, velocity and time delta per note event, and selecting the best pitch, velocity and time delta in that note event according to the best probabilty to the given `genre`. With the best possible values, it moves on to the next note event and repeats.\n",
    "\n",
    "This process will always reproduce the same output for a given genre, since it is synthesizing the trained dataset, but higher validation accuracies will make the genre more distinguishable. However, you can also use it to complete an incomplete .mid track, as long as it is under `CAPACITY`. To do this, follow the instructions below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d5f8a4",
   "metadata": {},
   "source": [
    "Firstly, save your .mid file anywhere under the directory \\Data. Then modify the value of `name_of_your_midi_file` to the appropriate filename, making sure it is a string that ends in .mid. Afterwards, just run the cell, and expect a good output in the \\Output folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e669a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_your_midi_file = ''\n",
    "\n",
    "\n",
    "\n",
    "###############################################\n",
    "os.chdir(WORKING_DIRECTORY)\n",
    "mid = MidiFile(name_of_your_midi_file, clip = True)\n",
    "notesList = getNotes(mid,0)\n",
    "\n",
    "if len(notesList) > CAPACITY:\n",
    "    print(\"Your .mid file is larger than CAPACITY, so this generator won't do anything.\")\n",
    "else:\n",
    "    out = generate(notesList, 'Classical', tolerance, lowest_pitch, highest_pitch, quietest_note, loudest_note, fastest_note, slowest_note)\n",
    "    \n",
    "    os.chdir(WORKING_DIRECTORY)\n",
    "    os.chdir('..')\n",
    "    os.chdir(os.getcwd() + \"\\\\\" + \"Output\")\n",
    "\n",
    "    mid = MidiFile()\n",
    "    track = MidiTrack()\n",
    "\n",
    "    for msg in out:\n",
    "        track.append(msg)\n",
    "\n",
    "    mid.tracks.append(track)\n",
    "\n",
    "    mid.save('completion_song.mid')\n",
    "    print(\"Saved completion_song.mid to \" + os.getcwd())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
