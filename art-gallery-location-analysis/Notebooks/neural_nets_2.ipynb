{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import random, time\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to complete problem 1, fill in the following with your code\n",
    "\n",
    "def ReLU(x,deriv = False):\n",
    "    ######################### your code goes here ########################\n",
    "    if deriv:\n",
    "        return np.diag((x>0).astype(int))\n",
    "    return [max(0,x[i]) for i in range(len(x))]\n",
    "\n",
    "def Linear(x,deriv = False):\n",
    "    ######################### your code goes here ########################\n",
    "    if deriv:\n",
    "        return np.identity(len(x))\n",
    "    return x\n",
    "\n",
    "def Sigmoid(x,deriv = False):\n",
    "    ######################### your code goes here ########################\n",
    "    if deriv:\n",
    "        return np.diag(Sigmoid(x,False)*(1-Sigmoid(x,False)))\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def Squared(x,deriv = False):\n",
    "    ######################### your code goes here ########################\n",
    "    if deriv:\n",
    "        return np.diag([2*x[i] for i in range(len(x))])\n",
    "    return x**2\n",
    "\n",
    "def Softmax(x,deriv = False):\n",
    "    ######################### your code goes here ########################\n",
    "    if deriv:\n",
    "        gx = Softmax(x,deriv = False)\n",
    "        return np.diag(gx) - np.outer(gx,gx)\n",
    "    denom = sum([np.exp(x[i]) for i in range(len(x))])\n",
    "    return np.array([np.exp(x[i])/denom for i in range(len(x))])\n",
    "\n",
    "\n",
    "# Note: Nx and y are always numpy arrays (for 'bce' they always have only one entry)\n",
    "# when deriv = False the output must be a number and when deriv = True the output must be a vector\n",
    "def loss(Nx,y,cost_type,deriv = False):\n",
    "    if cost_type == 'se':\n",
    "        if deriv:\n",
    "            return 2*(Nx-y).T\n",
    "        return LA.norm(Nx-y,2)**2\n",
    "    elif cost_type == 'ce':\n",
    "        if deriv:\n",
    "            return -y.T@np.diag(np.array([1/Nx[i] for i in range(len(Nx))]))\n",
    "        return -np.inner(y,np.log(Nx))\n",
    "    elif cost_type == 'bce':\n",
    "        if deriv:\n",
    "            return np.array([-y[0]/Nx[0]+(1-y[0])/(1-Nx[0])])\n",
    "        return -y[0]*np.log(Nx[0])-(1-y[0])*np.log(1-Nx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(W,B,G,x):\n",
    "    ######################### your code goes here ########################\n",
    "    D = len(W)\n",
    "    feeds = []\n",
    "    for l in range(D):\n",
    "        s = W[l]@x+B[l]\n",
    "        feeds.append([x,s])\n",
    "        #print(x,s)\n",
    "        x = G[l+1](s)\n",
    "    feeds.append([G[D](s)])\n",
    "    return feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deltas(X_feeds,Y,W,B,G,verbose = False, cost_type = 'se'):\n",
    "    ######################### your code goes here ########################\n",
    "    D = len(W)\n",
    "    deltas_dict = {}\n",
    "    for i in X_feeds.keys():\n",
    "        deltas_dict[i]=[]\n",
    "        l = D-1\n",
    "        xD = X_feeds[i][l+1][0]\n",
    "        sl = X_feeds[i][l][1]\n",
    "        delta = loss(xD,Y[i,:],cost_type,deriv = True)@G[l+1](sl,True)\n",
    "        if verbose:\n",
    "            print(f'l = {l}')\n",
    "            print(f'the shape of x({D}): {xD.shape}')\n",
    "            print(f'the shape of s({l}): {sl.shape}')\n",
    "            print(f'the shape of delta({l}): {delta.shape}')\n",
    "        deltas_dict[i].append(delta)\n",
    "        while l>=1:\n",
    "            l-=1\n",
    "            sl = X_feeds[i][l][1]\n",
    "            if verbose:\n",
    "                print(f'the shape of s({l}): {sl.shape}')\n",
    "                print(f'the shape of delta({l}): {deltas_dict[i][-1].shape}')\n",
    "                print(f'the shape of W[{l+1}]: {W[l+1].shape}')\n",
    "            delta = (deltas_dict[i][-1]@W[l+1])@G[l+1](sl,True)\n",
    "            if verbose:\n",
    "                print(f'l = {l}')\n",
    "                print(f'the shape of s({l}): {sl.shape}')\n",
    "                print(f'the shape of deltas[{i}][{l}]: {deltas_dict[i][-1].shape}')\n",
    "                print(f'the shape of W[{l+1}]: {W[l+1].shape}')\n",
    "                print(f'delta = {delta}')\n",
    "            deltas_dict[i].append(delta)\n",
    "        deltas_dict[i].reverse()\n",
    "    return deltas_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grads(X,Y,W,B,G,batch, lambda_ = 0, verbose = False,cost_type = 'se'):\n",
    "    ######################### your code goes here ########################\n",
    "    dWs = []\n",
    "    dBs = []\n",
    "    m,D = len(X),len(W)\n",
    "    X_feeds = {}\n",
    "    for i in batch:\n",
    "        x=X[i,:]\n",
    "        feeds=feedforward(W,B,G,x)\n",
    "        X_feeds[i] = feeds\n",
    "    X_deltas = deltas(X_feeds,Y,W,B,G,verbose,cost_type)\n",
    "    for l in range(D):\n",
    "        if verbose:\n",
    "            print(f'the shape of s({l}): {X_feeds[i][l][0]}')\n",
    "            print(f'the shape of delta({l}): {X_deltas[i][l]}')\n",
    "        dWs.append(1/m*sum([np.outer(X_deltas[i][l],X_feeds[i][l][0]) for i in batch]) + 2*lambda_*W[l])\n",
    "        dBs.append(1/m*sum([X_deltas[i][l] for i in batch]))\n",
    "    return dWs,dBs,X_feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_iters should be a multiple of 100\n",
    "def fit(X,Y,arch,G,alpha = 1e-9, momentum = .01, batch_size = 100, \n",
    "        lambda_ = 0, max_iters = 100,verbose = False, cost_type = 'se',print_costs = True):\n",
    "    ######################### your code goes here ########################\n",
    "    W,B,VW,VB = [],[],[],[]\n",
    "    D,m = len(G)-1,len(X)\n",
    "    for l in range(D):\n",
    "        W.append(np.random.normal(0, 2/(arch[l+1]+arch[l]), size=(arch[l+1], arch[l])))\n",
    "        B.append(np.zeros(arch[l+1]))\n",
    "        VW.append(np.zeros(W[l].shape))\n",
    "        VB.append(np.zeros(B[l].shape))\n",
    "    epochs = 0\n",
    "    costs = []\n",
    "    grad_norms = []\n",
    "    while epochs<=max_iters:\n",
    "        batch = random.sample(range(m),batch_size)\n",
    "        dWs,dBs,feeds = grads(X,Y,W,B,G,batch,lambda_,verbose,cost_type)\n",
    "        cost = 0\n",
    "        grad_norm = 0\n",
    "        for l in range(D):\n",
    "            grad_norm += LA.norm(W[l],2)\n",
    "            grad_norm += LA.norm(B[l],2)\n",
    "        grad_norms.append(grad_norm)\n",
    "        for i in batch:\n",
    "            Nx = feeds[i][D][0]\n",
    "            cost += loss(Nx,Y[i],cost_type)/batch_size\n",
    "        costs.append(cost)\n",
    "        if epochs%(np.floor(max_iters/30))==0 and print_costs:\n",
    "            print(f'epoch: {epochs}')\n",
    "            print(f'           cost: {cost}')\n",
    "        if verbose:\n",
    "            print('computed grads')\n",
    "        for l in range(D):\n",
    "            VW[l] = momentum*VW[l]-alpha*dWs[l]\n",
    "            W[l] = W[l] + VW[l]\n",
    "            VB[l] = momentum*VB[l]-alpha*dBs[l]\n",
    "            B[l] = B[l] + VB[l]\n",
    "        epochs+=1\n",
    "    return W,B,costs,grad_norms\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
