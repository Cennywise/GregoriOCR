{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034abf95",
   "metadata": {},
   "source": [
    "# <center> Computational Homework 2</center>\n",
    "\n",
    "In this notebook we look at some computational problems in probability theory and optimization. Throughout the notebook, vectors and matrices should always be represented as numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48add7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to import needed modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import random, time\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e9e5e7",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Consider a random variable $\\mathrm{x}$ whose value is the sum of the roll values of 5 dice. One is 4-sided, one is 6-sided, one is 8-sided, one is 12-sided, one is 20-sided. First write a function `average_sum` to compute the average value of $\\mathrm{x}$ after `n` rolls. Use the `random.randint` function to generate random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815293cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to complete problem 1, fill in the following with your code\n",
    "def average_sum(n): \n",
    "    ######################### your code goes here ########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32480438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function 5 times. Should get close to the same value each time. (no input needed)\n",
    "for i in range(5):\n",
    "    print(average_sum(100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6ed6e0",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Continuing from the previous problem, define a function `histogram()` and a function `expectation_value()`. `histogram` should return a dictionary `hist` whose keys are possible outcomes for $\\mathrm{x}$ and whose values are the frequencies of the keys: that is, the number of possible ways to roll the dice and get that key. Hint: use 5 nested for loops to iterate through all possible outcomes and use this to compute the frequencies. Create a list and at each step, add a sum to the list. Then use the `Counter` function imported from the `collections` library to convert this to a dictionary of frequencies. The function `expectation_value` should compute the expectation value of $\\mathrm{x}$ exactly using the definition of the expectation value. Use the output from the `histogram` function to compute the probabilities needed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd10b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to complete problem 1, fill in the following with your code\n",
    "def histogram():\n",
    "    ######################### your code goes here ########################\n",
    "\n",
    "def expectation_value(): \n",
    "    ######################### your code goes here ########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30397d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting histogram of possible values (should look normal due to the central limit theorem) (no input needed)\n",
    "hist = histogram()\n",
    "plt.bar(hist.keys(), hist.values(), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e07a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your expectation value. It should coincide with the result of the previous problem. (no input needed)\n",
    "expectation_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed9999",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "In this problem, implement the gradient descent algorithm to find \n",
    "\n",
    "$$\\mathbf{v}^* = \\underset{\\mathbf{v}\\in\\mathbb{R}^{n+1}}{\\mathrm{argmin}} J(\\mathbf{v})$$\n",
    "\n",
    "where $J$ is the function defined in Problem 2 of the theoretical homework (so you should do that problem first). Your implementation should involve only vectors and matrices and avoid any reference to components of the vectors and matrices (this is called a *vectorized implementation*). This is made possible by the matrix differentiation rules we studied in lecture.\n",
    "\n",
    "You will complete functions `J(X,y,v)`, `DJ(X,y,v)`, and `GD_linreg(X,y,alpha,epsilon,max_iters)` where `X` is the dataset $\\mathbf{X}$, `alpha` is the step size $\\alpha$ and `epsilon` is the parameter $\\epsilon$ for the stopping condition discussed in class. The input `v` is a vector of length equal to the number of columns of `X` plus one. The input `y` is the vector $\\mathbf{y}$ of labels above. The input `max_iters` (with default value 10000) is the maximum number of iterations you want to allow before forcing the loop to break. The output of `J(X,y,v)` is the value $J(\\mathbf{v})$. The output of `DJ(X,y,v)` is the value of $\\nabla_{\\mathbf{v}}J(\\mathbf{v})$. The output of `GD_linreg` should be a tuple `(v,costs)` where `v` is an approximate solution for $\\mathbf{v}^*$ and `costs` is a list of all of the cost function values at each step.\n",
    "\n",
    "As a precaution, keep track of the number `i` of steps taken, and stop iterating after `max_iters` steps. On the first step, and after each 100 steps, print a statement using an f-string that says `f'after {i} steps the cost is {costs[i]}'`. Also print this statement after the loop ends.\n",
    "\n",
    "## Hints\n",
    "\n",
    "To get the matrix $\\hat{\\mathbf{X}}$ you should use the `np.concatenate` function to concatenate a column of all 1's with the matrix $\\mathbf{X}$. You can use the function `np.ones` to create this.\n",
    "\n",
    "The inputs (besides alpha and epsilon) are all numpy arrays of appropriate dimensions. You may use `@` or `np.matmul` for matrix multiplication and `X.T` to compute the transpose of a numpy array `X`.\n",
    "\n",
    "If you pick a random initialization for `v`, the cost function will likely explode. I suggest initializing with the zero vector.\n",
    "\n",
    "For the stopping condition, instead of using the one I stated in class, you could also try stopping when `abs(costs[i] - costs[i-1])<epsilon`. Feel free to experiment with this condition though (for example you could use the condition stated in lecture, or use `costs[i]-costs[i-100]`), and the same goes for the following problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51c88fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to complete problem 3, fill in the following with your code\n",
    "def J(X,y,v):\n",
    "    ######################### your code goes here ########################\n",
    "\n",
    "    \n",
    "def DJ(X,y,v):\n",
    "    ######################### your code goes here ########################\n",
    "\n",
    "\n",
    "def GD_linreg(X,y,alpha,epsilon,max_iters = 10000): \n",
    "    ######################### your code goes here ########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82482d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a dataset to test the model (no input needed)\n",
    "X = np.random.normal(0, 500, size=(4000,2))\n",
    "y = np.array([[np.random.normal(3,2)*point[0]+np.random.normal(4,2)*point[1]+np.random.normal(5,5)] for point in X])\n",
    "Xhat = np.concatenate((np.ones((len(X),1)),X), axis = 1)\n",
    "# visualize the dataset \n",
    "plot_figure = go.Figure(data=[go.Scatter3d(x=Xhat[:,1], y=Xhat[:,2], z=[r[0] for r in y], mode='markers',marker=dict(size=2))])\n",
    "plotly.offline.iplot(plot_figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADJUST THE PARAMETERS alpha and epsilon until you get good performance (input needed)\n",
    "# idea: If step size is too small, it will take too long to converge. Too large and cost values will explode.\n",
    "# idea: If epsilon is too small, it will never terminate. Too small and it terminates too early.\n",
    "# The current values are probably VERY bad and will lead to horrible computational errors.\n",
    "# You can change max_iters as well if you'd like to\n",
    "# See if you can tune it so that it ends before max_iters, but also not too fast (maybe around 100 iters)\n",
    "alpha = 3*10e-3\n",
    "epsilon = .01\n",
    "max_iters = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1824f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the gradient descent algorithm (no input needed)\n",
    "v,costs = GD_linreg(X,y,alpha,epsilon,max_iters)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc14000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the cost versus number of iterations (no input needed)\n",
    "plt.plot(costs)\n",
    "plt.xlabel('number of iterations')\n",
    "plt.ylabel('Cost J(v)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e20f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how well your result fits the dataset (no input needed)\n",
    "yy = [r[0] for r in y]\n",
    "trace = go.Scatter3d(x=Xhat[:,1], y=Xhat[:,2], z=[r[0] for r in y], mode='markers',marker=dict(size=2))\n",
    "xs,ys = Xhat[:,1],Xhat[:,2]\n",
    "xxx = np.outer(np.linspace(min(xs), max(xs), 30), np.ones(30))\n",
    "yyy = np.outer(np.linspace(min(ys), max(ys), 30), np.ones(30)).T\n",
    "zzz = v[0]+v[1]*xxx + v[2]*yyy\n",
    "# Configure the layout.\n",
    "layout = go.Layout(margin={'l': 0, 'r': 0, 'b': 0, 't': 0})\n",
    "data = [trace,go.Surface(x=xxx, y=yyy, z=zzz, showscale=False, opacity=0.5)]\n",
    "# Render the plot.\n",
    "plot_figure = go.Figure(data=data, layout=layout)\n",
    "plotly.offline.iplot(plot_figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a3cbe4",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "Now use the Hessian to automatically pick the step size in yourgradient descent algorithm. Use your result from theoretical problem 2 in homework 2 to implement the Hessian and use this to compute the step size `alpha`. Complete the function `GD_linreg_improved` below. You can copy your work from the gradient descent algorithm above and make the necessary modifications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56d3fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD_linreg_improved(X,y,epsilon,max_iters=10000): \n",
    "    ######################### your code goes here ########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030d3169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the value of epsilon (and max_iters if you want)\n",
    "epsilon = .01\n",
    "max_iters = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db07b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the second order gradient descent algorithm (no input needed)\n",
    "# You should find a similar value of v and cost (hopefully improved)\n",
    "v,costs = GD_linreg_improved(X,y,epsilon)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3628c204",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "This is a continuation of problem 3 in theoretical homework 2, so make sure to solve that problem first. Implement gradient descent for logistic regression by filling in the functions `J`, `DJ`, and `GD_logreg` below. Inputs and outputs are similar to those for linear regression but with the cost function \n",
    "\n",
    "$$J(\\mathbf{v}) = -(\\mathbf{1} - \\mathbf{y})^\\top\\mathbf{Log}(\\mathbf{1} - \\mathbf{G}(\\hat{\\mathbf{X}}\\mathbf{v})) - \\mathbf{y}^\\top\\mathbf{Log}(\\mathbf{G}(\\hat{\\mathbf{X}}\\mathbf{v})).$$\n",
    "\n",
    "The functions `G` and `Log` are provided. You should use the Hessian information to automatically pick the step size. \n",
    "\n",
    "Again, print the cost function value on the initial step, after each 100 steps, and also after the loop ends. Again, initialize with the zero vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dece4844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to complete problem 4, fill in the following with your code    \n",
    "def G(v): \n",
    "    return 1/(1+np.exp(-v))\n",
    "\n",
    "def Log(v): \n",
    "    return np.log(v)\n",
    "\n",
    "def J(X,y,v):\n",
    "    ######################### your code goes here ########################\n",
    "\n",
    "    \n",
    "def DJ(X,y,v):\n",
    "    ######################### your code goes here ########################\n",
    "\n",
    "\n",
    "def GD_logreg(X,y,epsilon,max_iters): \n",
    "    ######################### your code goes here ########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4769587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating and plotting a dataset to test our logistic regression (no input needed)\n",
    "# The output v defines a plane and the cost function is a measure of how well this plane does\n",
    "# in separating red points from blue points\n",
    "points = np.random.normal(0, 50, size=(3000,3))\n",
    "y,c = [],[]\n",
    "for point in points:\n",
    "    if 3*point[0]-7*point[1]+12*point[2]<4:\n",
    "        rnd = random.randint(-10,10)\n",
    "        if rnd>-8:\n",
    "            y.append([1])\n",
    "            c.append('red')\n",
    "        else:\n",
    "            y.append([0])\n",
    "            c.append('blue')\n",
    "    else:\n",
    "        rnd = random.randint(-10,10)\n",
    "        if rnd>-8:\n",
    "            y.append([0])\n",
    "            c.append('blue')\n",
    "        else:\n",
    "            y.append([1])\n",
    "            c.append('red')\n",
    "X,y = np.array(points), np.array(y)\n",
    "Xhat = np.concatenate((np.ones((len(X),1)),X), axis = 1)\n",
    "# visualize the dataset \n",
    "plot_figure = go.Figure(data=[go.Scatter3d(x=Xhat[:,1], y=Xhat[:,2], z=Xhat[:,3], mode='markers',marker=dict(size=2,color=c))])\n",
    "plotly.offline.iplot(plot_figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b5ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different values of epsilon until you get good performance\n",
    "epsilon = 10e-6\n",
    "max_iters = 10000\n",
    "v,costs=GD_logreg(X,y,epsilon,max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ababe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the cost versus number of iterations (no input needed)\n",
    "plt.plot(costs)\n",
    "plt.xlabel('number of iterations')\n",
    "plt.ylabel('Cost J(v)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a0ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how well your result fits the dataset (no input needed)\n",
    "# The value of v found in gradient descent defines a plane which should do a good job of\n",
    "# separating the blue dots from the red dots\n",
    "yy = [r[0] for r in y]\n",
    "trace = go.Scatter3d(x=Xhat[:,1], y=Xhat[:,2], z=Xhat[:,3], mode='markers',marker=dict(size=3,color=c))\n",
    "xs = Xhat[:,1]\n",
    "ys = Xhat[:,2]\n",
    "xxx = np.outer(np.linspace(min(xs), max(xs), 30), np.ones(30))\n",
    "yyy = np.outer(np.linspace(min(ys), max(ys), 30), np.ones(30)).T\n",
    "zzz = (v[0]+v[1]*xxx + v[2]*yyy)/(-v[3])\n",
    "# Configure the layout.\n",
    "layout = go.Layout(margin={'l': 0, 'r': 0, 'b': 0, 't': 0})\n",
    "data = [trace,go.Surface(x=xxx, y=yyy, z=zzz, showscale=False, opacity=0.5)]\n",
    "# Render the plot.\n",
    "plot_figure = go.Figure(data=data, layout=layout)\n",
    "plotly.offline.iplot(plot_figure)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
