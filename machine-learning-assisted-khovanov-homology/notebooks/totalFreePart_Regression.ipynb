{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29374061",
   "metadata": {},
   "source": [
    "# Step1. Read in the parsed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "583f84b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T00:13:27.807043Z",
     "start_time": "2022-12-05T00:13:27.803166Z"
    }
   },
   "outputs": [],
   "source": [
    "# import useful libraries for data preprocessing\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg as LA\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc193f59",
   "metadata": {},
   "source": [
    "Run this cell to check your current working directory. It should return the top folder \"machine-learning-assisted-khovanov-homology\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05997dd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-04T23:34:02.772222Z",
     "start_time": "2022-12-04T23:34:02.765240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/guoyihan/Documents/GitHub/MAT_180_ML_Projects/machine-learning-assisted-khovanov-homology/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c1cdda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-04T23:34:04.106057Z",
     "start_time": "2022-12-04T23:34:04.102389Z"
    }
   },
   "outputs": [],
   "source": [
    "#Run this cell once if still in the notebooks folder.\n",
    "#Note that running this command multiple times might get you too high in the directory tree so be \n",
    "#cautious running this cell\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c451adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression with dataset_no_repeats.csv dataset.\n",
    "# change the dataset to get new report for prediction using total free part\n",
    "df = pd.read_csv(\"data/dataset_A.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01f4d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>braid</th>\n",
       "      <th>khovanov_homology</th>\n",
       "      <th>free_part</th>\n",
       "      <th>torsion_part</th>\n",
       "      <th>free_part_count</th>\n",
       "      <th>torsion_part_count</th>\n",
       "      <th>total_num_FP_per_row</th>\n",
       "      <th>total_num_FP_per_column</th>\n",
       "      <th>jones_polynomial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-1, -1, -2, 2, -1, 2, -2, -1, -1]</td>\n",
       "      <td>{-15: {-5: Z}, -13: {-5: 0, -4: C2}, -11: {-5:...</td>\n",
       "      <td>{(-15, -5): 1, (-11, -4): 1, (-11, -3): 1, (-7...</td>\n",
       "      <td>{(-13, -4): {2: 1}, (-9, -2): {2: 1}}</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>{-15: 1, -11: 2, -7: 1, -5: 1, -3: 1}</td>\n",
       "      <td>{-5: 1, -4: 1, -3: 1, -2: 1, 0: 2}</td>\n",
       "      <td>{-7: -1, -6: 1, -5: -1, -4: 1, -2: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1, 3, 3, 2, 3, 3, -3, 1]</td>\n",
       "      <td>{3: {0: Z}, 5: {0: Z, 1: 0, 2: 0, 3: 0}, 7: {0...</td>\n",
       "      <td>{(3, 0): 1, (5, 0): 1, (7, 2): 2, (11, 3): 2, ...</td>\n",
       "      <td>{(9, 3): {2: 2}, (13, 5): {2: 1}, (15, 6): {2:...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>{3: 1, 5: 1, 7: 2, 11: 3, 13: 1, 15: 1, 17: 1}</td>\n",
       "      <td>{0: 2, 2: 2, 3: 2, 4: 1, 5: 2, 6: 1}</td>\n",
       "      <td>{2: 1, 4: 2, 5: -2, 6: 1, 7: -2, 8: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-3, -1, -1, 1, -2, 1, -3, -1, -3]</td>\n",
       "      <td>{-15: {-6: 0, -5: 0, -4: 0}, -13: {-6: 0, -5: ...</td>\n",
       "      <td>{(-9, -3): 1, (-5, -2): 1, (-3, 0): 1, (-1, 0)...</td>\n",
       "      <td>{(-7, -2): {2: 1}}</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{-9: 1, -5: 1, -3: 1, -1: 1}</td>\n",
       "      <td>{-3: 1, -2: 1, 0: 2}</td>\n",
       "      <td>{-4: -1, -3: 1, -1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-3, -3, 1, 2, 2, 2, -3, 3, -3]</td>\n",
       "      <td>{-7: {-3: Z}, -5: {-3: 0, -2: C2, -1: 0, 0: 0}...</td>\n",
       "      <td>{(-7, -3): 1, (-3, -2): 1, (-3, -1): 1, (-1, 0...</td>\n",
       "      <td>{(-5, -2): {2: 1}, (-1, 0): {2: 1}, (1, 1): {2...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>{-7: 1, -3: 2, -1: 2, 1: 2, 3: 2, 7: 1}</td>\n",
       "      <td>{-3: 1, -2: 1, -1: 1, 0: 4, 1: 1, 2: 1, 3: 1}</td>\n",
       "      <td>{-3: -1, -2: 1, -1: -1, 0: 3, 1: -1, 2: 1, 3: -1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-1, -3, 2, 3, -1, -1, 1, -2, -1]</td>\n",
       "      <td>{-11: {-5: 0, -4: 0, -3: 0}, -9: {-5: 0, -4: 0...</td>\n",
       "      <td>{(-9, -3): 1, (-5, -2): 1, (-3, 0): 1, (-1, 0)...</td>\n",
       "      <td>{(-7, -2): {2: 1}}</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{-9: 1, -5: 1, -3: 1, -1: 1}</td>\n",
       "      <td>{-3: 1, -2: 1, 0: 2}</td>\n",
       "      <td>{-4: -1, -3: 1, -1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>[1, 1, 1, 3, -2, -3, 1, -2, 1]</td>\n",
       "      <td>{-3: {-3: 0, -2: 0}, -1: {-3: 0, -2: 0, -1: 0,...</td>\n",
       "      <td>{(3, 0): 1, (5, 0): 1, (7, 2): 1, (11, 3): 1, ...</td>\n",
       "      <td>{(9, 3): {2: 1}, (13, 5): {2: 1}}</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>{3: 1, 5: 1, 7: 1, 11: 2, 15: 1}</td>\n",
       "      <td>{0: 2, 2: 1, 3: 1, 4: 1, 5: 1}</td>\n",
       "      <td>{2: 1, 4: 1, 5: -1, 6: 1, 7: -1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>[-2, 1, -3, 2, 2, 2, 1, 1, -2]</td>\n",
       "      <td>{-3: {-3: 0, -2: 0, -1: 0, 0: 0, 1: 0}, -1: {-...</td>\n",
       "      <td>{(1, 0): 2, (3, 0): 1, (3, 1): 1, (5, 1): 1, (...</td>\n",
       "      <td>{(3, 1): {2: 1}, (5, 2): {2: 1}, (7, 3): {2: 2...</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>{1: 2, 3: 2, 5: 3, 7: 2, 9: 3, 11: 2, 13: 1, 1...</td>\n",
       "      <td>{0: 3, 1: 2, 2: 3, 3: 3, 4: 2, 5: 2, 6: 1}</td>\n",
       "      <td>{1: 2, 2: -2, 3: 3, 4: -3, 5: 2, 6: -2, 7: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>[-2, 1, 1, -2, 1, 3, 2, 3, -2]</td>\n",
       "      <td>{-5: {-3: 0, -2: 0}, -3: {-3: 0, -2: 0, -1: 0,...</td>\n",
       "      <td>{(1, 0): 1, (3, 0): 1, (5, 2): 1, (9, 3): 1}</td>\n",
       "      <td>{(7, 3): {2: 1}}</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1, 3: 1, 5: 1, 9: 1}</td>\n",
       "      <td>{0: 2, 2: 1, 3: 1}</td>\n",
       "      <td>{1: 1, 3: 1, 4: -1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>[-2, -2, -1, -3, -2, -2, -1, -2, -1]</td>\n",
       "      <td>{-21: {-9: 0, -8: 0, -7: 0, -6: 0, -5: 0}, -19...</td>\n",
       "      <td>{(-17, -5): 1, (-15, -5): 1, (-13, -4): 1, (-1...</td>\n",
       "      <td>{(-11, -2): {2: 1}}</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>{-17: 1, -15: 1, -13: 2, -11: 1, -9: 1, -7: 1,...</td>\n",
       "      <td>{-5: 2, -4: 2, -3: 1, -2: 1, 0: 2}</td>\n",
       "      <td>{-8: -1, -5: 1, -3: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>[2, -1, 2, 2, 2, -1, 2, 2, -3]</td>\n",
       "      <td>{-3: {-3: 0, -2: 0}, -1: {-3: 0, -2: Z, -1: 0,...</td>\n",
       "      <td>{(-1, -2): 1, (3, -1): 1, (3, 0): 3, (5, 0): 1...</td>\n",
       "      <td>{(1, -1): {2: 1}, (5, 1): {2: 2}, (7, 2): {2: ...</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>{-1: 1, 3: 4, 5: 2, 7: 4, 9: 3, 11: 3, 13: 3, ...</td>\n",
       "      <td>{-2: 1, -1: 1, 0: 4, 1: 3, 2: 3, 3: 4, 4: 3, 5...</td>\n",
       "      <td>{0: 1, 1: -1, 2: 3, 3: -3, 4: 3, 5: -4, 6: 3, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1081 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     braid  \\\n",
       "0       [-1, -1, -2, 2, -1, 2, -2, -1, -1]   \n",
       "1             [1, 1, 3, 3, 2, 3, 3, -3, 1]   \n",
       "2       [-3, -1, -1, 1, -2, 1, -3, -1, -3]   \n",
       "3          [-3, -3, 1, 2, 2, 2, -3, 3, -3]   \n",
       "4        [-1, -3, 2, 3, -1, -1, 1, -2, -1]   \n",
       "...                                    ...   \n",
       "1076        [1, 1, 1, 3, -2, -3, 1, -2, 1]   \n",
       "1077        [-2, 1, -3, 2, 2, 2, 1, 1, -2]   \n",
       "1078        [-2, 1, 1, -2, 1, 3, 2, 3, -2]   \n",
       "1079  [-2, -2, -1, -3, -2, -2, -1, -2, -1]   \n",
       "1080        [2, -1, 2, 2, 2, -1, 2, 2, -3]   \n",
       "\n",
       "                                      khovanov_homology  \\\n",
       "0     {-15: {-5: Z}, -13: {-5: 0, -4: C2}, -11: {-5:...   \n",
       "1     {3: {0: Z}, 5: {0: Z, 1: 0, 2: 0, 3: 0}, 7: {0...   \n",
       "2     {-15: {-6: 0, -5: 0, -4: 0}, -13: {-6: 0, -5: ...   \n",
       "3     {-7: {-3: Z}, -5: {-3: 0, -2: C2, -1: 0, 0: 0}...   \n",
       "4     {-11: {-5: 0, -4: 0, -3: 0}, -9: {-5: 0, -4: 0...   \n",
       "...                                                 ...   \n",
       "1076  {-3: {-3: 0, -2: 0}, -1: {-3: 0, -2: 0, -1: 0,...   \n",
       "1077  {-3: {-3: 0, -2: 0, -1: 0, 0: 0, 1: 0}, -1: {-...   \n",
       "1078  {-5: {-3: 0, -2: 0}, -3: {-3: 0, -2: 0, -1: 0,...   \n",
       "1079  {-21: {-9: 0, -8: 0, -7: 0, -6: 0, -5: 0}, -19...   \n",
       "1080  {-3: {-3: 0, -2: 0}, -1: {-3: 0, -2: Z, -1: 0,...   \n",
       "\n",
       "                                              free_part  \\\n",
       "0     {(-15, -5): 1, (-11, -4): 1, (-11, -3): 1, (-7...   \n",
       "1     {(3, 0): 1, (5, 0): 1, (7, 2): 2, (11, 3): 2, ...   \n",
       "2     {(-9, -3): 1, (-5, -2): 1, (-3, 0): 1, (-1, 0)...   \n",
       "3     {(-7, -3): 1, (-3, -2): 1, (-3, -1): 1, (-1, 0...   \n",
       "4     {(-9, -3): 1, (-5, -2): 1, (-3, 0): 1, (-1, 0)...   \n",
       "...                                                 ...   \n",
       "1076  {(3, 0): 1, (5, 0): 1, (7, 2): 1, (11, 3): 1, ...   \n",
       "1077  {(1, 0): 2, (3, 0): 1, (3, 1): 1, (5, 1): 1, (...   \n",
       "1078       {(1, 0): 1, (3, 0): 1, (5, 2): 1, (9, 3): 1}   \n",
       "1079  {(-17, -5): 1, (-15, -5): 1, (-13, -4): 1, (-1...   \n",
       "1080  {(-1, -2): 1, (3, -1): 1, (3, 0): 3, (5, 0): 1...   \n",
       "\n",
       "                                           torsion_part  free_part_count  \\\n",
       "0                 {(-13, -4): {2: 1}, (-9, -2): {2: 1}}                6   \n",
       "1     {(9, 3): {2: 2}, (13, 5): {2: 1}, (15, 6): {2:...               10   \n",
       "2                                    {(-7, -2): {2: 1}}                4   \n",
       "3     {(-5, -2): {2: 1}, (-1, 0): {2: 1}, (1, 1): {2...               10   \n",
       "4                                    {(-7, -2): {2: 1}}                4   \n",
       "...                                                 ...              ...   \n",
       "1076                  {(9, 3): {2: 1}, (13, 5): {2: 1}}                6   \n",
       "1077  {(3, 1): {2: 1}, (5, 2): {2: 1}, (7, 3): {2: 2...               16   \n",
       "1078                                   {(7, 3): {2: 1}}                4   \n",
       "1079                                {(-11, -2): {2: 1}}                8   \n",
       "1080  {(1, -1): {2: 1}, (5, 1): {2: 2}, (7, 2): {2: ...               22   \n",
       "\n",
       "      torsion_part_count                               total_num_FP_per_row  \\\n",
       "0                      2              {-15: 1, -11: 2, -7: 1, -5: 1, -3: 1}   \n",
       "1                      4     {3: 1, 5: 1, 7: 2, 11: 3, 13: 1, 15: 1, 17: 1}   \n",
       "2                      1                       {-9: 1, -5: 1, -3: 1, -1: 1}   \n",
       "3                      4            {-7: 1, -3: 2, -1: 2, 1: 2, 3: 2, 7: 1}   \n",
       "4                      1                       {-9: 1, -5: 1, -3: 1, -1: 1}   \n",
       "...                  ...                                                ...   \n",
       "1076                   2                   {3: 1, 5: 1, 7: 1, 11: 2, 15: 1}   \n",
       "1077                   7  {1: 2, 3: 2, 5: 3, 7: 2, 9: 3, 11: 2, 13: 1, 1...   \n",
       "1078                   1                           {1: 1, 3: 1, 5: 1, 9: 1}   \n",
       "1079                   1  {-17: 1, -15: 1, -13: 2, -11: 1, -9: 1, -7: 1,...   \n",
       "1080                  10  {-1: 1, 3: 4, 5: 2, 7: 4, 9: 3, 11: 3, 13: 3, ...   \n",
       "\n",
       "                                total_num_FP_per_column  \\\n",
       "0                    {-5: 1, -4: 1, -3: 1, -2: 1, 0: 2}   \n",
       "1                  {0: 2, 2: 2, 3: 2, 4: 1, 5: 2, 6: 1}   \n",
       "2                                  {-3: 1, -2: 1, 0: 2}   \n",
       "3         {-3: 1, -2: 1, -1: 1, 0: 4, 1: 1, 2: 1, 3: 1}   \n",
       "4                                  {-3: 1, -2: 1, 0: 2}   \n",
       "...                                                 ...   \n",
       "1076                     {0: 2, 2: 1, 3: 1, 4: 1, 5: 1}   \n",
       "1077         {0: 3, 1: 2, 2: 3, 3: 3, 4: 2, 5: 2, 6: 1}   \n",
       "1078                                 {0: 2, 2: 1, 3: 1}   \n",
       "1079                 {-5: 2, -4: 2, -3: 1, -2: 1, 0: 2}   \n",
       "1080  {-2: 1, -1: 1, 0: 4, 1: 3, 2: 3, 3: 4, 4: 3, 5...   \n",
       "\n",
       "                                       jones_polynomial  \n",
       "0                 {-7: -1, -6: 1, -5: -1, -4: 1, -2: 1}  \n",
       "1                {2: 1, 4: 2, 5: -2, 6: 1, 7: -2, 8: 1}  \n",
       "2                                {-4: -1, -3: 1, -1: 1}  \n",
       "3     {-3: -1, -2: 1, -1: -1, 0: 3, 1: -1, 2: 1, 3: -1}  \n",
       "4                                {-4: -1, -3: 1, -1: 1}  \n",
       "...                                                 ...  \n",
       "1076                   {2: 1, 4: 1, 5: -1, 6: 1, 7: -1}  \n",
       "1077      {1: 2, 2: -2, 3: 3, 4: -3, 5: 2, 6: -2, 7: 1}  \n",
       "1078                                {1: 1, 3: 1, 4: -1}  \n",
       "1079                             {-8: -1, -5: 1, -3: 1}  \n",
       "1080  {0: 1, 1: -1, 2: 3, 3: -3, 4: 3, 5: -4, 6: 3, ...  \n",
       "\n",
       "[1081 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9621150e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x7f91a22bdee0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at data distribution using seaborn plot\n",
    "sns.pairplot(df[['free_part_count','torsion_part_count']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0eaad1",
   "metadata": {},
   "source": [
    "# Step2. Trian the LinearRegression Model&PolynomialRegression Model and find the parameters using the function we built ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fe527da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T00:26:25.507037Z",
     "start_time": "2022-12-05T00:26:25.502756Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import functions built in class\n",
    "from scripts.predict_accuracy import prediction, accuracy\n",
    "from scripts.GDLinearReg import J, DJ, GD_linreg_improved,fit,add_poly_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "488c78e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T00:26:26.752380Z",
     "start_time": "2022-12-05T00:26:26.743545Z"
    }
   },
   "outputs": [],
   "source": [
    "X = (np.array(df.free_part_count)).reshape(-1, 1)\n",
    "y = (np.array(df.torsion_part_count)).reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7246a8b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T00:26:27.501140Z",
     "start_time": "2022-12-05T00:26:27.495115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 648\n",
      "Size of validation set: 216\n",
      "Size of testing set: 217\n"
     ]
    }
   ],
   "source": [
    "print(f'Size of training set: {len(X_train)}')\n",
    "print(f'Size of validation set: {len(X_val)}')\n",
    "print(f'Size of testing set: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db8bba7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running polynomial regression of degree 1 \n",
      "\n",
      "After 0 steps the cost is 38.27777777777778\n",
      "After 7 steps the cost is 0.06655716986065746\n",
      "\n",
      "Final cost is 0.0665571698601681\n",
      "\n",
      "Accuracy of training set is: 0.9830246913580247\n",
      "Accuracy of validation set is: 0.9907407407407407\n",
      "Accuracy of test set is: 0.9907834101382489\n",
      "[[-1.05314558]\n",
      " [ 0.50169459]]\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "degree = 1\n",
    "\n",
    "v, costs = fit(X_train, y_train, epsilon = 1e-10, lambda_ = 0, max_iters = 10000, poly_terms = degree)\n",
    "\n",
    "print(f'Accuracy of training set is: {accuracy(add_poly_terms(X_train, degree),v,y_train)}')\n",
    "print(f'Accuracy of validation set is: {accuracy(add_poly_terms(X_val, degree),v,y_val)}')\n",
    "print(f'Accuracy of test set is: {accuracy(add_poly_terms(X_test, degree),v,y_test)}')\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9998bd13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T00:26:40.146433Z",
     "start_time": "2022-12-05T00:26:39.723041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running polynomial regression of degree 2 \n",
      "\n",
      "After 0 steps the cost is 38.27777777777778\n",
      "After 1000 steps the cost is 0.07021340327357983\n",
      "After 2000 steps the cost is 0.06663442968299402\n",
      "After 3000 steps the cost is 0.0665587157158285\n",
      "After 4000 steps the cost is 0.06655711397224101\n",
      "After 4076 steps the cost is 0.0665571051789823\n",
      "\n",
      "Final cost is 0.06655710507959942\n",
      "\n",
      "Accuracy of training set is: 0.9830246913580247\n",
      "Accuracy of validation set is: 0.9907407407407407\n",
      "Accuracy of test set is: 0.9907834101382489\n",
      "[[-1.05211142e+00]\n",
      " [ 5.01548805e-01]\n",
      " [ 3.47220282e-06]]\n"
     ]
    }
   ],
   "source": [
    "# Polynomial Regression\n",
    "degree = 2\n",
    "\n",
    "v, costs = fit(X_train, y_train, epsilon = 1e-10, lambda_ = 0, max_iters = 10000, poly_terms = degree)\n",
    "\n",
    "print(f'Accuracy of training set is: {accuracy(add_poly_terms(X_train, degree),v,y_train)}')\n",
    "print(f'Accuracy of validation set is: {accuracy(add_poly_terms(X_val, degree),v,y_val)}')\n",
    "print(f'Accuracy of test set is: {accuracy(add_poly_terms(X_test, degree),v,y_test)}')\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed0e93f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to test with the dataset that has 2_component link or 3-componet link.\n",
    "# also a dataset combined them together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a4c460",
   "metadata": {},
   "source": [
    "# Step3. Train the LinearRegression model from Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35cf7bea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T00:14:22.790272Z",
     "start_time": "2022-12-05T00:14:22.781443Z"
    }
   },
   "outputs": [],
   "source": [
    "# try to make prediction using LinearRegression and libraries from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# need to reshape X because there is only one feature in X (i.e. X is currently a row vector, need to convert it to a column vector)\n",
    "X = (np.array(df.free_part_count)).reshape(-1, 1)\n",
    "y = (np.array(df.torsion_part_count))\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5993a08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T00:07:09.899898Z",
     "start_time": "2022-12-05T00:07:09.896042Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries for Polynomial Regression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d31bdbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute accuracy\n",
    "def find_accuracy(y_pred, y_true):\n",
    "    accur_count = 0\n",
    "    for index,y in enumerate(y_pred):\n",
    "        if y == math.ceil(y_true[index]):\n",
    "            accur_count += 1\n",
    "    return accur_count/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "727551fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T00:17:05.383237Z",
     "start_time": "2022-12-05T00:17:05.312434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Features: [1,x,x**2,...,x**1]\n",
      "[ 1. 10.]\n",
      "Polynomial Features: [1,x,x**2,...,x**1]\n",
      "[1. 4.]\n",
      "Polynomial Features: [1,x,x**2,...,x**1]\n",
      "[ 1. 14.]\n",
      "Polynomial Features: [1,x,x**2,...,x**2]\n",
      "[  1.  10. 100.]\n",
      "Polynomial Features: [1,x,x**2,...,x**2]\n",
      "[ 1.  4. 16.]\n",
      "Polynomial Features: [1,x,x**2,...,x**2]\n",
      "[  1.  14. 196.]\n",
      "Polynomial Features: [1,x,x**2,...,x**3]\n",
      "[   1.   10.  100. 1000.]\n",
      "Polynomial Features: [1,x,x**2,...,x**3]\n",
      "[ 1.  4. 16. 64.]\n",
      "Polynomial Features: [1,x,x**2,...,x**3]\n",
      "[1.000e+00 1.400e+01 1.960e+02 2.744e+03]\n",
      "Polynomial Features: [1,x,x**2,...,x**4]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04]\n",
      "Polynomial Features: [1,x,x**2,...,x**4]\n",
      "[  1.   4.  16.  64. 256.]\n",
      "Polynomial Features: [1,x,x**2,...,x**4]\n",
      "[1.0000e+00 1.4000e+01 1.9600e+02 2.7440e+03 3.8416e+04]\n",
      "Polynomial Features: [1,x,x**2,...,x**5]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05]\n",
      "Polynomial Features: [1,x,x**2,...,x**5]\n",
      "[1.000e+00 4.000e+00 1.600e+01 6.400e+01 2.560e+02 1.024e+03]\n",
      "Polynomial Features: [1,x,x**2,...,x**5]\n",
      "[1.00000e+00 1.40000e+01 1.96000e+02 2.74400e+03 3.84160e+04 5.37824e+05]\n",
      "Polynomial Features: [1,x,x**2,...,x**6]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06]\n",
      "Polynomial Features: [1,x,x**2,...,x**6]\n",
      "[1.000e+00 4.000e+00 1.600e+01 6.400e+01 2.560e+02 1.024e+03 4.096e+03]\n",
      "Polynomial Features: [1,x,x**2,...,x**6]\n",
      "[1.000000e+00 1.400000e+01 1.960000e+02 2.744000e+03 3.841600e+04\n",
      " 5.378240e+05 7.529536e+06]\n",
      "Polynomial Features: [1,x,x**2,...,x**7]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06 1.e+07]\n",
      "Polynomial Features: [1,x,x**2,...,x**7]\n",
      "[1.0000e+00 4.0000e+00 1.6000e+01 6.4000e+01 2.5600e+02 1.0240e+03\n",
      " 4.0960e+03 1.6384e+04]\n",
      "Polynomial Features: [1,x,x**2,...,x**7]\n",
      "[1.00000000e+00 1.40000000e+01 1.96000000e+02 2.74400000e+03\n",
      " 3.84160000e+04 5.37824000e+05 7.52953600e+06 1.05413504e+08]\n",
      "Polynomial Features: [1,x,x**2,...,x**8]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06 1.e+07 1.e+08]\n",
      "Polynomial Features: [1,x,x**2,...,x**8]\n",
      "[1.0000e+00 4.0000e+00 1.6000e+01 6.4000e+01 2.5600e+02 1.0240e+03\n",
      " 4.0960e+03 1.6384e+04 6.5536e+04]\n",
      "Polynomial Features: [1,x,x**2,...,x**8]\n",
      "[1.00000000e+00 1.40000000e+01 1.96000000e+02 2.74400000e+03\n",
      " 3.84160000e+04 5.37824000e+05 7.52953600e+06 1.05413504e+08\n",
      " 1.47578906e+09]\n",
      "Polynomial Features: [1,x,x**2,...,x**9]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06 1.e+07 1.e+08 1.e+09]\n",
      "Polynomial Features: [1,x,x**2,...,x**9]\n",
      "[1.00000e+00 4.00000e+00 1.60000e+01 6.40000e+01 2.56000e+02 1.02400e+03\n",
      " 4.09600e+03 1.63840e+04 6.55360e+04 2.62144e+05]\n",
      "Polynomial Features: [1,x,x**2,...,x**9]\n",
      "[1.00000000e+00 1.40000000e+01 1.96000000e+02 2.74400000e+03\n",
      " 3.84160000e+04 5.37824000e+05 7.52953600e+06 1.05413504e+08\n",
      " 1.47578906e+09 2.06610468e+10]\n",
      "Polynomial Features: [1,x,x**2,...,x**10]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06 1.e+07 1.e+08 1.e+09\n",
      " 1.e+10]\n",
      "Polynomial Features: [1,x,x**2,...,x**10]\n",
      "[1.000000e+00 4.000000e+00 1.600000e+01 6.400000e+01 2.560000e+02\n",
      " 1.024000e+03 4.096000e+03 1.638400e+04 6.553600e+04 2.621440e+05\n",
      " 1.048576e+06]\n",
      "Polynomial Features: [1,x,x**2,...,x**10]\n",
      "[1.00000000e+00 1.40000000e+01 1.96000000e+02 2.74400000e+03\n",
      " 3.84160000e+04 5.37824000e+05 7.52953600e+06 1.05413504e+08\n",
      " 1.47578906e+09 2.06610468e+10 2.89254655e+11]\n",
      "Polynomial Features: [1,x,x**2,...,x**11]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06 1.e+07 1.e+08 1.e+09\n",
      " 1.e+10 1.e+11]\n",
      "Polynomial Features: [1,x,x**2,...,x**11]\n",
      "[1.000000e+00 4.000000e+00 1.600000e+01 6.400000e+01 2.560000e+02\n",
      " 1.024000e+03 4.096000e+03 1.638400e+04 6.553600e+04 2.621440e+05\n",
      " 1.048576e+06 4.194304e+06]\n",
      "Polynomial Features: [1,x,x**2,...,x**11]\n",
      "[1.00000000e+00 1.40000000e+01 1.96000000e+02 2.74400000e+03\n",
      " 3.84160000e+04 5.37824000e+05 7.52953600e+06 1.05413504e+08\n",
      " 1.47578906e+09 2.06610468e+10 2.89254655e+11 4.04956517e+12]\n",
      "Polynomial Features: [1,x,x**2,...,x**12]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06 1.e+07 1.e+08 1.e+09\n",
      " 1.e+10 1.e+11 1.e+12]\n",
      "Polynomial Features: [1,x,x**2,...,x**12]\n",
      "[1.0000000e+00 4.0000000e+00 1.6000000e+01 6.4000000e+01 2.5600000e+02\n",
      " 1.0240000e+03 4.0960000e+03 1.6384000e+04 6.5536000e+04 2.6214400e+05\n",
      " 1.0485760e+06 4.1943040e+06 1.6777216e+07]\n",
      "Polynomial Features: [1,x,x**2,...,x**12]\n",
      "[1.00000000e+00 1.40000000e+01 1.96000000e+02 2.74400000e+03\n",
      " 3.84160000e+04 5.37824000e+05 7.52953600e+06 1.05413504e+08\n",
      " 1.47578906e+09 2.06610468e+10 2.89254655e+11 4.04956517e+12\n",
      " 5.66939124e+13]\n",
      "Polynomial Features: [1,x,x**2,...,x**13]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06 1.e+07 1.e+08 1.e+09\n",
      " 1.e+10 1.e+11 1.e+12 1.e+13]\n",
      "Polynomial Features: [1,x,x**2,...,x**13]\n",
      "[1.0000000e+00 4.0000000e+00 1.6000000e+01 6.4000000e+01 2.5600000e+02\n",
      " 1.0240000e+03 4.0960000e+03 1.6384000e+04 6.5536000e+04 2.6214400e+05\n",
      " 1.0485760e+06 4.1943040e+06 1.6777216e+07 6.7108864e+07]\n",
      "Polynomial Features: [1,x,x**2,...,x**13]\n",
      "[1.00000000e+00 1.40000000e+01 1.96000000e+02 2.74400000e+03\n",
      " 3.84160000e+04 5.37824000e+05 7.52953600e+06 1.05413504e+08\n",
      " 1.47578906e+09 2.06610468e+10 2.89254655e+11 4.04956517e+12\n",
      " 5.66939124e+13 7.93714773e+14]\n",
      "Polynomial Features: [1,x,x**2,...,x**14]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06 1.e+07 1.e+08 1.e+09\n",
      " 1.e+10 1.e+11 1.e+12 1.e+13 1.e+14]\n",
      "Polynomial Features: [1,x,x**2,...,x**14]\n",
      "[1.00000000e+00 4.00000000e+00 1.60000000e+01 6.40000000e+01\n",
      " 2.56000000e+02 1.02400000e+03 4.09600000e+03 1.63840000e+04\n",
      " 6.55360000e+04 2.62144000e+05 1.04857600e+06 4.19430400e+06\n",
      " 1.67772160e+07 6.71088640e+07 2.68435456e+08]\n",
      "Polynomial Features: [1,x,x**2,...,x**14]\n",
      "[1.00000000e+00 1.40000000e+01 1.96000000e+02 2.74400000e+03\n",
      " 3.84160000e+04 5.37824000e+05 7.52953600e+06 1.05413504e+08\n",
      " 1.47578906e+09 2.06610468e+10 2.89254655e+11 4.04956517e+12\n",
      " 5.66939124e+13 7.93714773e+14 1.11120068e+16]\n"
     ]
    }
   ],
   "source": [
    "# Find the degree of Polynomial Regression that gives the best prediction accuracy\n",
    "model_degrees_and_scores = {}\n",
    "model_degrees_and_accuracy = {}\n",
    "for current_degree in range(1,15):\n",
    "    polynomial_features= PolynomialFeatures(degree=current_degree)\n",
    "    X_poly_train_deg = polynomial_features.fit_transform(X_train)\n",
    "    print(f'Polynomial Features: [1,x,x**2,...,x**{current_degree}]')\n",
    "    print(X_poly_train_deg[0])\n",
    "    \n",
    "    X_poly_val_deg = polynomial_features.fit_transform(X_val)\n",
    "    print(f'Polynomial Features: [1,x,x**2,...,x**{current_degree}]')\n",
    "    print(X_poly_val_deg[0])\n",
    "    \n",
    "\n",
    "    X_poly_test_deg = polynomial_features.fit_transform(X_test)\n",
    "    print(f'Polynomial Features: [1,x,x**2,...,x**{current_degree}]')\n",
    "    print(X_poly_test_deg[0])\n",
    "\n",
    "    polyreg = LinearRegression().fit(X_poly_train_deg, y_train)\n",
    "    \n",
    "    train_score = polyreg.score(X_poly_train_deg,y_train)\n",
    "    val_score = polyreg.score(X_poly_val_deg,y_val)\n",
    "    test_score = polyreg.score(X_poly_test_deg,y_test)\n",
    "        \n",
    "    y_train_pred = polyreg.predict(X_poly_train_deg)\n",
    "    y_val_pred = polyreg.predict(X_poly_val_deg)\n",
    "    y_test_pred = polyreg.predict(X_poly_test_deg)\n",
    "    train_accuracy = find_accuracy(y_train, y_train_pred)\n",
    "    val_accuracy = find_accuracy(y_val, y_val_pred)\n",
    "    test_accuracy = find_accuracy(y_test, y_test_pred)\n",
    "    \n",
    "    model_degrees_and_scores[current_degree] = (train_score, val_score, test_score)\n",
    "    model_degrees_and_accuracy[current_degree] = (train_accuracy, val_accuracy, test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a5de91b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T00:22:44.760390Z",
     "start_time": "2022-12-05T00:22:44.753551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1 scores: (0.9961854542032902, 0.996689906167883, 0.9986253583557888)\n",
      "Degree 2 scores: (0.9961855431112161, 0.9966895074290567, 0.9986249143257563)\n",
      "Degree 3 scores: (0.9961932965785659, 0.9966981368106852, 0.9986212759008535)\n",
      "Degree 4 scores: (0.996219219700024, 0.9967179279103181, 0.998606321386437)\n",
      "Degree 5 scores: (0.9962596431360705, 0.9967519307061131, 0.998581222802471)\n",
      "Degree 6 scores: (0.9962954369649488, 0.996767244909191, 0.998557268965047)\n",
      "Degree 7 scores: (0.9963098365320182, 0.9967699981628567, 0.9985500241346432)\n",
      "Degree 8 scores: (0.9963105464454888, 0.9967680059963694, 0.9985490659396984)\n",
      "Degree 9 scores: (0.9963072188838022, 0.9967600761688417, 0.9985332524282866)\n",
      "Degree 10 scores: (0.9914089185049131, 0.9905652177069153, 0.9915613731545233)\n",
      "Degree 11 scores: (0.9768961727036134, 0.9755531682353894, 0.9735762151174491)\n",
      "Degree 12 scores: (0.9509284710094854, 0.948162826290044, 0.9365058987896278)\n",
      "Degree 13 scores: (0.9122816148839594, 0.9053223194910859, 0.8848826725937541)\n",
      "Degree 14 scores: (0.7593371541072363, 0.7303381104310236, 0.6943945842316875)\n"
     ]
    }
   ],
   "source": [
    "for i, scores in model_degrees_and_scores.items():\n",
    "    print(f'Degree {i} scores: {scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e13db6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1 scores: (0.9567901234567902, 0.9537037037037037, 0.9631336405529954)\n",
      "Degree 2 scores: (0.9567901234567902, 0.9537037037037037, 0.9631336405529954)\n",
      "Degree 3 scores: (0.9290123456790124, 0.9166666666666666, 0.9447004608294931)\n",
      "Degree 4 scores: (0.8981481481481481, 0.9120370370370371, 0.8940092165898618)\n",
      "Degree 5 scores: (0.8472222222222222, 0.875, 0.8663594470046083)\n",
      "Degree 6 scores: (0.5817901234567902, 0.5925925925925926, 0.6129032258064516)\n",
      "Degree 7 scores: (0.5987654320987654, 0.5879629629629629, 0.6267281105990783)\n",
      "Degree 8 scores: (0.5416666666666666, 0.5277777777777778, 0.5391705069124424)\n",
      "Degree 9 scores: (0.5555555555555556, 0.5138888888888888, 0.5483870967741935)\n",
      "Degree 10 scores: (0.558641975308642, 0.5092592592592593, 0.543778801843318)\n",
      "Degree 11 scores: (0.5740740740740741, 0.5787037037037037, 0.6036866359447005)\n",
      "Degree 12 scores: (0.24228395061728394, 0.25, 0.2764976958525346)\n",
      "Degree 13 scores: (0.14351851851851852, 0.12037037037037036, 0.1889400921658986)\n",
      "Degree 14 scores: (0.1388888888888889, 0.13425925925925927, 0.1152073732718894)\n"
     ]
    }
   ],
   "source": [
    "for i, accuracy in model_degrees_and_accuracy.items():\n",
    "    print(f'Degree {i} scores: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
