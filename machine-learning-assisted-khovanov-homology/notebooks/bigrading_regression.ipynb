{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b66f3f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T02:46:23.693447Z",
     "start_time": "2022-12-06T02:46:23.689555Z"
    }
   },
   "source": [
    "# Step 1. Import needed libraries and scripts\n",
    "\n",
    "This also requires setting up the correct working directory to be the top folder 'machine-learning-assisted-khovanov-homology'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f247bcb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T21:49:56.427362Z",
     "start_time": "2022-12-07T21:49:56.420528Z"
    }
   },
   "outputs": [],
   "source": [
    "# import useful libraries for data preprocessing\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg as LA\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c463cbe",
   "metadata": {},
   "source": [
    "Run this cell to check your current working directory. It should return the top folder \"machine-learning-assisted-khovanov-homology\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf80f75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:11:48.471208Z",
     "start_time": "2022-12-07T19:11:48.465487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/wuwj2/Desktop/jupyter/MAT_180_ML_Projects/machine-learning-assisted-khovanov-homology'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff05a75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:11:46.438851Z",
     "start_time": "2022-12-07T19:11:46.434180Z"
    }
   },
   "outputs": [],
   "source": [
    "#Run this cell once if still in the notebooks folder.\n",
    "#Note that running this command multiple times might get you too high in the directory tree so be \n",
    "#cautious running this cell\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e6b4d2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:11:49.561108Z",
     "start_time": "2022-12-07T19:11:49.359236Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import functions built in class\n",
    "from scripts.getGridsDimensions import find_max_min_row, find_max_min_col\n",
    "from scripts.polynomial import add_poly_terms\n",
    "from scripts.GDLinearReg import J, DJ, GD_linreg_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10bb84c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:32:13.003899Z",
     "start_time": "2022-12-07T19:32:12.964262Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataset_C.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b264c6",
   "metadata": {},
   "source": [
    "# Step 2. Train and test with a dataset (links with 1,2 and 3 components) \n",
    "\n",
    "Parse the data from a .csv file containing the free parts and torsion count.\n",
    "\n",
    "Since we want each bigrading to be its unique feature, we first need to find a bounding box for all possible bigradings using the getGridsDimensions script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a46f740",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:26:21.046122Z",
     "start_time": "2022-12-07T19:26:20.601546Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataset_C.csv')\n",
    "\n",
    "# Obtain the list of free_part dictionaries.\n",
    "# They are in the form {bigrading: value}\n",
    "fp_list = df['free_part'].to_list()\n",
    "fp_list = list(map(eval, fp_list))\n",
    "\n",
    "max_row, min_row = find_max_min_row(df)\n",
    "max_col, min_col = find_max_min_col(df)\n",
    "\n",
    "bigrading_list = []\n",
    "\n",
    "for i in range(min_row, max_row+1):\n",
    "    for j in range(min_col, max_col+1):\n",
    "        bigrading_list.append((i,j)) \n",
    "        \n",
    "# print(bigrading_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad06b8e",
   "metadata": {},
   "source": [
    "Train the model using links of different components separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "00410a37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:38:42.410745Z",
     "start_time": "2022-12-07T19:38:42.303000Z"
    }
   },
   "outputs": [],
   "source": [
    "L1_fp_list = list(map(eval, df[df.components == 1]['free_part'].to_list()))\n",
    "L2_fp_list = list(map(eval, df[df.components == 2]['free_part'].to_list()))\n",
    "L3_fp_list = list(map(eval, df[df.components == 3]['free_part'].to_list()))\n",
    "\n",
    "y1 = df[df.components == 1]['torsion_part_count'].to_numpy().reshape(-1,1)\n",
    "y2 = df[df.components == 2]['torsion_part_count'].to_numpy().reshape(-1,1)\n",
    "y3 = df[df.components == 3]['torsion_part_count'].to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7a7f76b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:39:13.897831Z",
     "start_time": "2022-12-07T19:39:13.894368Z"
    }
   },
   "outputs": [],
   "source": [
    "n = len(bigrading_list)\n",
    "m1, m2, m3 = len(y1), len(y2), len(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fd93cbed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T21:58:51.725224Z",
     "start_time": "2022-12-07T21:58:24.822224Z"
    }
   },
   "outputs": [],
   "source": [
    "X1, X2, X3 = np.zeros([m1,n]), np.zeros([m2,n]), np.zeros([m3,n])\n",
    "\n",
    "for i, fp in enumerate(L1_fp_list):\n",
    "    for key, val in fp.items():\n",
    "        X1[i,bigrading_list.index(key)] = val\n",
    "        \n",
    "for i, fp in enumerate(L2_fp_list):\n",
    "    for key, val in fp.items():\n",
    "        X2[i,bigrading_list.index(key)] = val\n",
    "        \n",
    "for i, fp in enumerate(L3_fp_list):\n",
    "    for key, val in fp.items():\n",
    "        X3[i,bigrading_list.index(key)] = val\n",
    "        \n",
    "X1 = add_poly_terms(X1,1)\n",
    "X2 = add_poly_terms(X2,1)\n",
    "X3 = add_poly_terms(X3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "16d176f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:33:59.741213Z",
     "start_time": "2022-12-07T23:33:59.686120Z"
    }
   },
   "outputs": [],
   "source": [
    "from scripts.predict_accuracy import prediction, accuracy\n",
    "\n",
    "\n",
    "#This fit function has been modified to not have the add_poly_terms built-in because the number is features in X is too\n",
    "#large for it to be used at all.\n",
    "def fit(X, y, epsilon, lambda_, max_iters = 10000):    \n",
    "    v, costs =  GD_linreg_improved(X, y, epsilon, lambda_, max_iters) \n",
    "    \n",
    "    print(f'\\nFinal cost is {costs[-1]}\\n')\n",
    "    return v, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b571448",
   "metadata": {},
   "source": [
    "## Step 2a. Training a model using only knots (single component links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1567ab0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:35:04.982098Z",
     "start_time": "2022-12-07T23:35:04.961546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set for 1-Links: 706\n",
      "Size of validation set for 1-Links: 177\n",
      "Size of testing set for 1-Links: 221\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into training, validation, and testing sets.\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=1)\n",
    "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(f'Size of training set for 1-Links: {len(X1_train)}')\n",
    "print(f'Size of validation set for 1-Links: {len(X1_val)}')\n",
    "print(f'Size of testing set for 1-Links: {len(X1_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0321faf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:36:28.884651Z",
     "start_time": "2022-12-07T23:35:08.699997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 steps the cost is 35.23512747875354\n",
      "After 817 steps the cost is 0.004400263527908442\n",
      "\n",
      "Final cost is 0.004390308430671085\n",
      "\n",
      "Accuracy of training set is: 0.9957507082152974\n",
      "Accuracy of validation set is: 0.9774011299435028\n",
      "Accuracy of test set is: 0.9728506787330317\n"
     ]
    }
   ],
   "source": [
    "v1, costs1 = fit(X1_train, y1_train, epsilon = 1e-5, lambda_ = 0, max_iters = 1000)\n",
    "\n",
    "print(f'Accuracy of training set is: {accuracy(X1_train,v1,y1_train)}')\n",
    "print(f'Accuracy of validation set is: {accuracy(X1_val,v1,y1_val)}')\n",
    "print(f'Accuracy of test set is: {accuracy(X1_test,v1,y1_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bbf832",
   "metadata": {},
   "source": [
    "## Step 2b. Training a model using only links with 2 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "18bb3334",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:36:28.898485Z",
     "start_time": "2022-12-07T23:36:28.888927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set for 2-Links: 196\n",
      "Size of validation set for 2-Links: 50\n",
      "Size of testing set for 2-Links: 62\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into training, validation, and testing sets.\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=1)\n",
    "X2_train, X2_val, y2_train, y2_val = train_test_split(X2_train, y2_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(f'Size of training set for 2-Links: {len(X2_train)}')\n",
    "print(f'Size of validation set for 2-Links: {len(X2_val)}')\n",
    "print(f'Size of testing set for 2-Links: {len(X2_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "67eb1664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:36:55.752804Z",
     "start_time": "2022-12-07T23:36:28.900492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 steps the cost is 26.535714285714285\n",
      "After 808 steps the cost is 0.00476627365888708\n",
      "\n",
      "Final cost is 0.004756324068640731\n",
      "\n",
      "Accuracy of training set is: 1.0\n",
      "Accuracy of validation set is: 0.98\n",
      "Accuracy of test set is: 0.967741935483871\n"
     ]
    }
   ],
   "source": [
    "v2, costs2 = fit(X2_train, y2_train, epsilon = 1e-5, lambda_ = 0, max_iters = 1000)\n",
    "\n",
    "print(f'Accuracy of training set is: {accuracy(X2_train,v2,y2_train)}')\n",
    "print(f'Accuracy of validation set is: {accuracy(X2_val,v2,y2_val)}')\n",
    "print(f'Accuracy of test set is: {accuracy(X2_test,v2,y2_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679bc8be",
   "metadata": {},
   "source": [
    "## Step 2c. Training a model using only links with 3 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0931ae45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:36:55.776197Z",
     "start_time": "2022-12-07T23:36:55.755205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set for 3-Links: 716\n",
      "Size of validation set for 3-Links: 179\n",
      "Size of testing set for 3-Links: 224\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into training, validation, and testing sets.\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=1)\n",
    "X3_train, X3_val, y3_train, y3_val = train_test_split(X3_train, y3_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(f'Size of training set for 3-Links: {len(X3_train)}')\n",
    "print(f'Size of validation set for 3-Links: {len(X3_val)}')\n",
    "print(f'Size of testing set for 3-Links: {len(X3_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d6aa5c8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:38:39.783022Z",
     "start_time": "2022-12-07T23:36:55.777751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 steps the cost is 38.92039106145252\n",
      "After 999 steps the cost is 0.2077239147315949\n",
      "\n",
      "Final cost is 0.20766693604842407\n",
      "\n",
      "Accuracy of training set is: 0.9259776536312849\n",
      "Accuracy of validation set is: 0.9608938547486033\n",
      "Accuracy of test set is: 0.9241071428571429\n"
     ]
    }
   ],
   "source": [
    "v3, costs3 = fit(X3_train, y3_train, epsilon = 1e-5, lambda_ = 0, max_iters = 1000)\n",
    "\n",
    "print(f'Accuracy of training set is: {accuracy(X3_train,v3,y3_train)}')\n",
    "print(f'Accuracy of validation set is: {accuracy(X3_val,v3,y3_val)}')\n",
    "print(f'Accuracy of test set is: {accuracy(X3_test,v3,y3_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363a54f6",
   "metadata": {},
   "source": [
    "Here are some random batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2d79c762",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:41:06.226324Z",
     "start_time": "2022-12-07T23:41:06.208914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Link, the 201th point has label [4] and is predicted to be 4\n",
      "1-Link, the 115th point has label [1] and is predicted to be 1\n",
      "1-Link, the 871th point has label [4] and is predicted to be 4\n",
      "1-Link, the 251th point has label [1] and is predicted to be 1\n",
      "1-Link, the 269th point has label [2] and is predicted to be 2\n",
      "1-Link, the 199th point has label [5] and is predicted to be 5\n",
      "1-Link, the 268th point has label [10] and is predicted to be 10\n",
      "1-Link, the 631th point has label [5] and is predicted to be 5\n",
      "1-Link, the 998th point has label [5] and is predicted to be 5\n",
      "1-Link, the 239th point has label [2] and is predicted to be 2\n",
      "\n",
      "2-Link, the 37th point has label [2] and is predicted to be 2\n",
      "2-Link, the 214th point has label [1] and is predicted to be 1\n",
      "2-Link, the 74th point has label [6] and is predicted to be 6\n",
      "2-Link, the 292th point has label [1] and is predicted to be 1\n",
      "2-Link, the 285th point has label [4] and is predicted to be 4\n",
      "2-Link, the 71th point has label [1] and is predicted to be 1\n",
      "2-Link, the 307th point has label [2] and is predicted to be 2\n",
      "2-Link, the 183th point has label [2] and is predicted to be 2\n",
      "2-Link, the 25th point has label [1] and is predicted to be 1\n",
      "2-Link, the 231th point has label [2] and is predicted to be 2\n"
     ]
    }
   ],
   "source": [
    "batch1 = random.choices(range(m1), k = 10)\n",
    "batch2 = random.choices(range(m2), k = 10)\n",
    "batch3 = random.choices(range(m3), k = 10)\n",
    "\n",
    "for i in batch1:\n",
    "    print(f'1-Link, the {i}th point has label {y1[i]} and is predicted to be {prediction(X1[i],v1)}')\n",
    "    \n",
    "print('')\n",
    "for i in batch2:\n",
    "    print(f'2-Link, the {i}th point has label {y2[i]} and is predicted to be {prediction(X2[i],v2)}')\n",
    "        \n",
    "print('')\n",
    "for i in batch3:\n",
    "    print(f'3-Link, the {i}th point has label {y2[i]} and is predicted to be {prediction(X2[i],v2)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
