{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b66f3f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T02:46:23.693447Z",
     "start_time": "2022-12-06T02:46:23.689555Z"
    }
   },
   "source": [
    "# Step 1. Import needed libraries and scripts\n",
    "\n",
    "This also requires setting up the correct working directory to be the top folder 'machine-learning-assisted-khovanov-homology'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f247bcb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T21:49:56.427362Z",
     "start_time": "2022-12-07T21:49:56.420528Z"
    }
   },
   "outputs": [],
   "source": [
    "# import useful libraries for data preprocessing\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg as LA\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c463cbe",
   "metadata": {},
   "source": [
    "Run this cell to check your current working directory. It should return the top folder \"machine-learning-assisted-khovanov-homology\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf80f75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:11:48.471208Z",
     "start_time": "2022-12-07T19:11:48.465487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/12428/Documents/GitHub/MAT_180_ML_Projects/machine-learning-assisted-khovanov-homology'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff05a75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:11:46.438851Z",
     "start_time": "2022-12-07T19:11:46.434180Z"
    }
   },
   "outputs": [],
   "source": [
    "#Run this cell once if still in the notebooks folder.\n",
    "#Note that running this command multiple times might get you too high in the directory tree so be \n",
    "#cautious running this cell\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e6b4d2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:11:49.561108Z",
     "start_time": "2022-12-07T19:11:49.359236Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import functions built in class\n",
    "from scripts.getGridsDimensions import find_max_min_row, find_max_min_col\n",
    "from scripts.polynomial import add_poly_terms\n",
    "from scripts.GDLinearReg import J, DJ, GD_linreg_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2331d7a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:32:13.003899Z",
     "start_time": "2022-12-07T19:32:12.964262Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataset_C.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b264c6",
   "metadata": {},
   "source": [
    "# Step 2. Train and test with a dataset (links with 1,2 and 3 components) \n",
    "\n",
    "Parse the data from a .csv file containing the free parts and torsion count.\n",
    "\n",
    "Since we want each bigrading to be its unique feature, we first need to find a bounding box for all possible bigradings using the getGridsDimensions script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a46f740",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:26:21.046122Z",
     "start_time": "2022-12-07T19:26:20.601546Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataset_C.csv')\n",
    "\n",
    "# Obtain the list of free_part dictionaries.\n",
    "# They are in the form {bigrading: value}\n",
    "fp_list = df['free_part'].to_list()\n",
    "fp_list = list(map(eval, fp_list))\n",
    "\n",
    "max_row, min_row = find_max_min_row(df)\n",
    "max_col, min_col = find_max_min_col(df)\n",
    "\n",
    "bigrading_list = []\n",
    "\n",
    "for i in range(min_row, max_row+1):\n",
    "    for j in range(min_col, max_col+1):\n",
    "        bigrading_list.append((i,j)) \n",
    "        \n",
    "# print(bigrading_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68667429",
   "metadata": {},
   "source": [
    "Train the model using links of different components separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7189780",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:38:42.410745Z",
     "start_time": "2022-12-07T19:38:42.303000Z"
    }
   },
   "outputs": [],
   "source": [
    "L_fp_list = list(map(eval, df['free_part'].to_list()))\n",
    "L1_fp_list = list(map(eval, df[df.components == 1]['free_part'].to_list()))\n",
    "L1_fp_list = list(map(eval, df[df.components == 1]['free_part'].to_list()))\n",
    "L2_fp_list = list(map(eval, df[df.components == 2]['free_part'].to_list()))\n",
    "L3_fp_list = list(map(eval, df[df.components == 3]['free_part'].to_list()))\n",
    "\n",
    "y = df['torsion_part_count'].to_numpy().reshape(-1,1)\n",
    "y1 = df[df.components == 1]['torsion_part_count'].to_numpy().reshape(-1,1)\n",
    "y2 = df[df.components == 2]['torsion_part_count'].to_numpy().reshape(-1,1)\n",
    "y3 = df[df.components == 3]['torsion_part_count'].to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7a7f76b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:39:13.897831Z",
     "start_time": "2022-12-07T19:39:13.894368Z"
    }
   },
   "outputs": [],
   "source": [
    "n = len(bigrading_list)\n",
    "m, m1, m2, m3 = len(y), len(y1), len(y2), len(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69ce42c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T21:58:51.725224Z",
     "start_time": "2022-12-07T21:58:24.822224Z"
    }
   },
   "outputs": [],
   "source": [
    "X, X1, X2, X3 = np.zeros([m,n]), np.zeros([m1,n]), np.zeros([m2,n]), np.zeros([m3,n])\n",
    "\n",
    "for i, fp in enumerate(L_fp_list):\n",
    "    for key, val in fp.items():\n",
    "        X[i,bigrading_list.index(key)] = val\n",
    "\n",
    "for i, fp in enumerate(L1_fp_list):\n",
    "    for key, val in fp.items():\n",
    "        X1[i,bigrading_list.index(key)] = val\n",
    "        \n",
    "for i, fp in enumerate(L2_fp_list):\n",
    "    for key, val in fp.items():\n",
    "        X2[i,bigrading_list.index(key)] = val\n",
    "        \n",
    "for i, fp in enumerate(L3_fp_list):\n",
    "    for key, val in fp.items():\n",
    "        X3[i,bigrading_list.index(key)] = val\n",
    "\n",
    "X = add_poly_terms(X,1)\n",
    "X1 = add_poly_terms(X1,1)\n",
    "X2 = add_poly_terms(X2,1)\n",
    "X3 = add_poly_terms(X3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16d176f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:33:59.741213Z",
     "start_time": "2022-12-07T23:33:59.686120Z"
    }
   },
   "outputs": [],
   "source": [
    "from scripts.predictAccuracy import prediction, accuracy\n",
    "\n",
    "\n",
    "#This fit function has been modified to not have the add_poly_terms built-in because the number is features in X is too\n",
    "#large for it to be used at all.\n",
    "def fit(X, y, epsilon, lambda_, max_iters = 10000):    \n",
    "    v, costs =  GD_linreg_improved(X, y, epsilon, lambda_, max_iters) \n",
    "    \n",
    "    print(f'\\nFinal cost is {costs[-1]}\\n')\n",
    "    return v, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cab233",
   "metadata": {},
   "source": [
    "## Step 2a. Training a model using only knots (single component links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1567ab0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:35:04.982098Z",
     "start_time": "2022-12-07T23:35:04.961546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set for 1-Links: 706\n",
      "Size of validation set for 1-Links: 177\n",
      "Size of testing set for 1-Links: 221\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into training, validation, and testing sets.\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=1)\n",
    "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(f'Size of training set for 1-Links: {len(X1_train)}')\n",
    "print(f'Size of validation set for 1-Links: {len(X1_val)}')\n",
    "print(f'Size of testing set for 1-Links: {len(X1_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0321faf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:36:28.884651Z",
     "start_time": "2022-12-07T23:35:08.699997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 steps the cost is 35.23512747875354\n",
      "After 817 steps the cost is 0.004400263527908442\n",
      "\n",
      "Final cost is 0.004390308430671085\n",
      "\n",
      "Accuracy of training set is: 0.9957507082152974\n",
      "Accuracy of validation set is: 0.9774011299435028\n",
      "Accuracy of test set is: 0.9728506787330317\n"
     ]
    }
   ],
   "source": [
    "v1, costs1 = fit(X1_train, y1_train, epsilon = 1e-5, lambda_ = 0, max_iters = 1000)\n",
    "\n",
    "print(f'Accuracy of training set is: {accuracy(X1_train,v1,y1_train)}')\n",
    "print(f'Accuracy of validation set is: {accuracy(X1_val,v1,y1_val)}')\n",
    "print(f'Accuracy of test set is: {accuracy(X1_test,v1,y1_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5e272d",
   "metadata": {},
   "source": [
    "## Step 2b. Training a model using only links with 2 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "deee5be2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:36:28.898485Z",
     "start_time": "2022-12-07T23:36:28.888927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set for 2-Links: 196\n",
      "Size of validation set for 2-Links: 50\n",
      "Size of testing set for 2-Links: 62\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into training, validation, and testing sets.\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=1)\n",
    "X2_train, X2_val, y2_train, y2_val = train_test_split(X2_train, y2_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(f'Size of training set for 2-Links: {len(X2_train)}')\n",
    "print(f'Size of validation set for 2-Links: {len(X2_val)}')\n",
    "print(f'Size of testing set for 2-Links: {len(X2_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "27ff7290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:36:55.752804Z",
     "start_time": "2022-12-07T23:36:28.900492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 steps the cost is 26.535714285714285\n",
      "After 808 steps the cost is 0.00476627365888708\n",
      "\n",
      "Final cost is 0.004756324068640731\n",
      "\n",
      "Accuracy of training set is: 1.0\n",
      "Accuracy of validation set is: 0.98\n",
      "Accuracy of test set is: 0.967741935483871\n"
     ]
    }
   ],
   "source": [
    "v2, costs2 = fit(X2_train, y2_train, epsilon = 1e-5, lambda_ = 0, max_iters = 1000)\n",
    "\n",
    "print(f'Accuracy of training set is: {accuracy(X2_train,v2,y2_train)}')\n",
    "print(f'Accuracy of validation set is: {accuracy(X2_val,v2,y2_val)}')\n",
    "print(f'Accuracy of test set is: {accuracy(X2_test,v2,y2_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d5276e",
   "metadata": {},
   "source": [
    "## Step 2c. Training a model using only links with 3 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d31a5cf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:36:55.776197Z",
     "start_time": "2022-12-07T23:36:55.755205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set for 3-Links: 716\n",
      "Size of validation set for 3-Links: 179\n",
      "Size of testing set for 3-Links: 224\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into training, validation, and testing sets.\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=1)\n",
    "X3_train, X3_val, y3_train, y3_val = train_test_split(X3_train, y3_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(f'Size of training set for 3-Links: {len(X3_train)}')\n",
    "print(f'Size of validation set for 3-Links: {len(X3_val)}')\n",
    "print(f'Size of testing set for 3-Links: {len(X3_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4735d37a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:38:39.783022Z",
     "start_time": "2022-12-07T23:36:55.777751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 steps the cost is 38.92039106145252\n",
      "After 999 steps the cost is 0.2077239147315949\n",
      "\n",
      "Final cost is 0.20766693604842407\n",
      "\n",
      "Accuracy of training set is: 0.9259776536312849\n",
      "Accuracy of validation set is: 0.9608938547486033\n",
      "Accuracy of test set is: 0.9241071428571429\n"
     ]
    }
   ],
   "source": [
    "v3, costs3 = fit(X3_train, y3_train, epsilon = 1e-5, lambda_ = 0, max_iters = 1000)\n",
    "\n",
    "print(f'Accuracy of training set is: {accuracy(X3_train,v3,y3_train)}')\n",
    "print(f'Accuracy of validation set is: {accuracy(X3_val,v3,y3_val)}')\n",
    "print(f'Accuracy of test set is: {accuracy(X3_test,v3,y3_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363a54f6",
   "metadata": {},
   "source": [
    "Here are some random batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5a1a38c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:41:57.014174Z",
     "start_time": "2022-12-07T23:41:56.998312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Link, the 774th point has label [2] and is predicted to be 2\n",
      "1-Link, the 513th point has label [7] and is predicted to be 7\n",
      "1-Link, the 979th point has label [3] and is predicted to be 3\n",
      "1-Link, the 561th point has label [4] and is predicted to be 4\n",
      "1-Link, the 418th point has label [9] and is predicted to be 9\n",
      "1-Link, the 467th point has label [4] and is predicted to be 4\n",
      "1-Link, the 958th point has label [8] and is predicted to be 8\n",
      "1-Link, the 500th point has label [2] and is predicted to be 2\n",
      "1-Link, the 246th point has label [1] and is predicted to be 2\n",
      "1-Link, the 113th point has label [7] and is predicted to be 7\n",
      "\n",
      "2-Link, the 210th point has label [4] and is predicted to be 4\n",
      "2-Link, the 165th point has label [1] and is predicted to be 1\n",
      "2-Link, the 65th point has label [1] and is predicted to be 1\n",
      "2-Link, the 131th point has label [2] and is predicted to be 2\n",
      "2-Link, the 197th point has label [2] and is predicted to be 2\n",
      "2-Link, the 256th point has label [7] and is predicted to be 7\n",
      "2-Link, the 168th point has label [1] and is predicted to be 1\n",
      "2-Link, the 297th point has label [1] and is predicted to be 1\n",
      "2-Link, the 164th point has label [3] and is predicted to be 3\n",
      "2-Link, the 79th point has label [1] and is predicted to be 1\n",
      "\n",
      "3-Link, the 215th point has label [4] and is predicted to be 4\n",
      "3-Link, the 684th point has label [1] and is predicted to be 1\n",
      "3-Link, the 635th point has label [6] and is predicted to be 6\n",
      "3-Link, the 800th point has label [8] and is predicted to be 8\n",
      "3-Link, the 517th point has label [3] and is predicted to be 4\n",
      "3-Link, the 966th point has label [14] and is predicted to be 14\n",
      "3-Link, the 1078th point has label [4] and is predicted to be 4\n",
      "3-Link, the 844th point has label [4] and is predicted to be 4\n",
      "3-Link, the 760th point has label [2] and is predicted to be 2\n",
      "3-Link, the 477th point has label [2] and is predicted to be 2\n"
     ]
    }
   ],
   "source": [
    "batch1 = random.choices(range(m1), k = 10)\n",
    "batch2 = random.choices(range(m2), k = 10)\n",
    "batch3 = random.choices(range(m3), k = 10)\n",
    "\n",
    "for i in batch1:\n",
    "    print(f'1-Link, the {i}th point has label {y1[i]} and is predicted to be {prediction(X1[i],v1)}')\n",
    "print('')\n",
    "for i in batch2:\n",
    "    print(f'2-Link, the {i}th point has label {y2[i]} and is predicted to be {prediction(X2[i],v2)}')\n",
    "print('')\n",
    "for i in batch3:\n",
    "    print(f'3-Link, the {i}th point has label {y3[i]} and is predicted to be {prediction(X3[i],v3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea67159",
   "metadata": {},
   "source": [
    "## Step 2d. Training a model using only links with multiple (1&2&3) components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5e684c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set for multiple-Links: 1619\n",
      "Size of validation set for multiple-Links: 405\n",
      "Size of testing set for multiple-Links: 507\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into training, validation, and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(f'Size of training set for multiple-Links: {len(X_train)}')\n",
    "print(f'Size of validation set for multiple-Links: {len(X_val)}')\n",
    "print(f'Size of testing set for multiple-Links: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a10d320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 steps the cost is 38.36380481778877\n",
      "After 999 steps the cost is 0.10799511073957528\n",
      "\n",
      "Final cost is 0.10795037586762624\n",
      "\n",
      "Accuracy of training set is: 0.9524397776405188\n",
      "Accuracy of validation set is: 0.9481481481481482\n",
      "Accuracy of test set is: 0.9408284023668639\n"
     ]
    }
   ],
   "source": [
    "v, costs = fit(X_train, y_train, epsilon = 1e-5, lambda_ = 0, max_iters = 1000)\n",
    "\n",
    "print(f'Accuracy of training set is: {accuracy(X_train,v,y_train)}')\n",
    "print(f'Accuracy of validation set is: {accuracy(X_val,v,y_val)}')\n",
    "print(f'Accuracy of test set is: {accuracy(X_test,v,y_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
